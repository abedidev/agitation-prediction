{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3080 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, f1_score, accuracy_score, \\\n",
    "    precision_score, recall_score, average_precision_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold, LeavePGroupsOut\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "%matplotlib inline\n",
    "# matplotlib.use('TkAgg')\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler  # install via: pip install imbalanced-learn\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from scipy.stats import skew\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "seed = 69\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/ali/PycharmProjects/tihm/dataset'\n",
    "\n",
    "dataset_06h = pd.read_csv(os.path.join(root, 'data-06h.csv'))\n",
    "dataset_12h = pd.read_csv(os.path.join(root, 'data-12h.csv'))\n",
    "dataset_24h = pd.read_csv(os.path.join(root, 'data-24h.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(dataset_06h)\n",
    "# display(dataset_12h)\n",
    "# display(dataset_24h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 117 89 18\n",
      "1752 135\n"
     ]
    }
   ],
   "source": [
    "# print(dataset_06h['agitation'].equals(dataset_06h['agitation-next']))\n",
    "# print(np.sum(dataset_06h['agitation']))\n",
    "# print(np.sum(dataset_06h['agitation-next']))\n",
    "\n",
    "# print(np.where(dataset_06h['agitation'] == 1))\n",
    "# print(np.where(dataset_06h['agitation-next'] == 1))\n",
    "\n",
    "print(np.sum(dataset_06h['agitation-four'] == 0),\n",
    "      np.sum(dataset_06h['agitation-four'] == 1),\n",
    "      np.sum(dataset_06h['agitation-four'] == 2),\n",
    "      np.sum(dataset_06h['agitation-four'] == 3))\n",
    "\n",
    "print(np.sum(dataset_06h['agitation-next'] == 0),\n",
    "      np.sum(dataset_06h['agitation-next'] == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "[0 1 2 3]\n",
      "349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], shape=(10790,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 55, 55, 55], shape=(10790,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset_06h\n",
    "# label = 'agitation-four'\n",
    "# label = 'agitation-next'\n",
    "label = 'agitation-four'\n",
    "\n",
    "y = np.array(dataset[[label]]).squeeze()\n",
    "\n",
    "# Binary\n",
    "# y[y == -1] = 0\n",
    "# y[y >= 1] = 1\n",
    "\n",
    "# QUATERNARY\n",
    "y[y == -1] = 0\n",
    "y[y == -10] = 0\n",
    "\n",
    "# dataset.drop(['agitation',\n",
    "#               'agitation-next',\n",
    "#               'agitation-four'],\n",
    "#               axis=1, inplace=True)\n",
    "\n",
    "ids = np.array(dataset['id']).squeeze()\n",
    "p = np.unique(ids, return_inverse=True)[1]\n",
    "\n",
    "print(np.isnan(y).sum())\n",
    "y = np.nan_to_num(y, nan=0)\n",
    "print(np.isnan(y).sum())\n",
    "print(np.isnan(p).sum())\n",
    "\n",
    "print(np.unique(y))\n",
    "print(y.sum())\n",
    "display(y)\n",
    "display(p)\n",
    "# display(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>6h</th>\n",
       "      <th>back-door</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>fridge-door</th>\n",
       "      <th>front-door</th>\n",
       "      <th>hallway</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>...</th>\n",
       "      <th>total-body-water</th>\n",
       "      <th>skin-temperature</th>\n",
       "      <th>blood-pressure</th>\n",
       "      <th>agitation</th>\n",
       "      <th>body-water</th>\n",
       "      <th>pulse</th>\n",
       "      <th>weight</th>\n",
       "      <th>body-temperature-label</th>\n",
       "      <th>agitation-next</th>\n",
       "      <th>agitation-four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0697d</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>00-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0697d</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>06-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0697d</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>12-18</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0697d</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>18-24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0697d</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>00-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>fd100</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>12-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>fd100</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>18-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>fd100</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>00-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>fd100</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>06-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>fd100</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>12-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10790 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        date     6h  back-door  bathroom  bedroom  fridge-door  \\\n",
       "0      0697d  2019-06-28  00-06        0.0       0.0      0.0          0.0   \n",
       "1      0697d  2019-06-28  06-12        0.0       0.0      0.0          0.0   \n",
       "2      0697d  2019-06-28  12-18       12.0       5.0     18.0         23.0   \n",
       "3      0697d  2019-06-28  18-24        2.0       2.0      6.0          0.0   \n",
       "4      0697d  2019-06-29  00-06        0.0       0.0      3.0          0.0   \n",
       "...      ...         ...    ...        ...       ...      ...          ...   \n",
       "10785  fd100  2019-06-29  12-18        0.0      10.0     19.0         17.0   \n",
       "10786  fd100  2019-06-29  18-24        0.0      13.0     16.0          3.0   \n",
       "10787  fd100  2019-06-30  00-06        0.0       0.0      0.0          0.0   \n",
       "10788  fd100  2019-06-30  06-12        0.0      13.0     34.0          5.0   \n",
       "10789  fd100  2019-06-30  12-18        0.0       3.0     29.0          3.0   \n",
       "\n",
       "       front-door  hallway  kitchen  ...  total-body-water  skin-temperature  \\\n",
       "0             0.0      0.0      0.0  ...               NaN               NaN   \n",
       "1             0.0      0.0      0.0  ...               NaN               NaN   \n",
       "2            27.0     30.0     57.0  ...              50.6               NaN   \n",
       "3             1.0     10.0     49.0  ...               NaN               NaN   \n",
       "4             0.0      0.0      0.0  ...               NaN               NaN   \n",
       "...           ...      ...      ...  ...               ...               ...   \n",
       "10785         9.0     25.0     56.0  ...               NaN               NaN   \n",
       "10786         3.0     23.0     22.0  ...               NaN               NaN   \n",
       "10787         0.0      0.0      0.0  ...               NaN               NaN   \n",
       "10788         8.0     17.0     38.0  ...               NaN               NaN   \n",
       "10789         4.0      6.0     50.0  ...               NaN               NaN   \n",
       "\n",
       "       blood-pressure  agitation  body-water  pulse  weight  \\\n",
       "0                 0.0        0.0         0.0    0.0     0.0   \n",
       "1                 0.0        0.0         0.0    0.0     0.0   \n",
       "2                 1.0        0.0         0.0    1.0     0.0   \n",
       "3                 0.0        0.0         0.0    0.0     0.0   \n",
       "4                 0.0        0.0         0.0    0.0     0.0   \n",
       "...               ...        ...         ...    ...     ...   \n",
       "10785             NaN        NaN         NaN    NaN     NaN   \n",
       "10786             NaN        NaN         NaN    NaN     NaN   \n",
       "10787             NaN        NaN         NaN    NaN     NaN   \n",
       "10788             NaN        NaN         NaN    NaN     NaN   \n",
       "10789             NaN        NaN         NaN    NaN     NaN   \n",
       "\n",
       "       body-temperature-label  agitation-next  agitation-four  \n",
       "0                         0.0             0.0               0  \n",
       "1                         0.0             0.0               0  \n",
       "2                         0.0             0.0               0  \n",
       "3                         0.0             0.0               0  \n",
       "4                         0.0             0.0               0  \n",
       "...                       ...             ...             ...  \n",
       "10785                     NaN             NaN             -10  \n",
       "10786                     NaN             NaN             -10  \n",
       "10787                     NaN             NaN             -10  \n",
       "10788                     NaN             NaN             -10  \n",
       "10789                     NaN             NaN             -10  \n",
       "\n",
       "[10790 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'date' '6h' 'back-door' 'bathroom' 'bedroom' 'fridge-door'\n",
      " 'front-door' 'hallway' 'kitchen' 'lounge' 'total-events'\n",
      " 'unique-locations' 'active-location-ratio' 'private-to-public-ratio'\n",
      " 'location-entropy' 'location-dominance-ratio' 'back-and-forth-count'\n",
      " 'num-transitions' 'back-door-count-max' 'back-door-count-mean'\n",
      " 'back-door-count-std' 'back-door-count-sum' 'bathroom-count-max'\n",
      " 'bathroom-count-mean' 'bathroom-count-std' 'bathroom-count-sum'\n",
      " 'bedroom-count-max' 'bedroom-count-mean' 'bedroom-count-std'\n",
      " 'bedroom-count-sum' 'fridge-door-count-max' 'fridge-door-count-mean'\n",
      " 'fridge-door-count-std' 'fridge-door-count-sum' 'front-door-count-max'\n",
      " 'front-door-count-mean' 'front-door-count-std' 'front-door-count-sum'\n",
      " 'hallway-count-max' 'hallway-count-mean' 'hallway-count-std'\n",
      " 'hallway-count-sum' 'kitchen-count-max' 'kitchen-count-mean'\n",
      " 'kitchen-count-std' 'kitchen-count-sum' 'lounge-count-max'\n",
      " 'lounge-count-mean' 'lounge-count-std' 'lounge-count-sum'\n",
      " 'body-temperature' 'body-weight' 'diastolic-blood-pressure' 'heart-rate'\n",
      " 'muscle-mass' 'systolic-blood-pressure' 'total-body-water'\n",
      " 'skin-temperature' 'blood-pressure' 'agitation' 'body-water' 'pulse'\n",
      " 'weight' 'body-temperature-label' 'agitation-next' 'agitation-four']\n"
     ]
    }
   ],
   "source": [
    "columns = dataset.columns\n",
    "dataset = dataset[columns]\n",
    "display(dataset)\n",
    "print(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imputation\n",
    "# import utils_data\n",
    "# importlib.reload(utils_data)\n",
    "# from utils_data import hierarchical_imputation\n",
    "\n",
    "# print(dataset.isna().sum().sum())\n",
    "\n",
    "# dataset = hierarchical_imputation(dataset)\n",
    "\n",
    "# print(dataset.isna().sum().sum())\n",
    "\n",
    "# dataset.drop([\n",
    "#     'id',\n",
    "#     'date',\n",
    "#     '6h',\n",
    "#     ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y.shape)\n",
    "# display(dataset)\n",
    "\n",
    "# dataset.to_csv(os.path.join(root, 'dataset_06h_imputed.csv'))\n",
    "# np.save('dataset_06h_y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10790,)\n",
      "(10790, 62)\n",
      "[0 1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>back-door</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>fridge-door</th>\n",
       "      <th>front-door</th>\n",
       "      <th>hallway</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>lounge</th>\n",
       "      <th>total-events</th>\n",
       "      <th>...</th>\n",
       "      <th>heart-rate</th>\n",
       "      <th>muscle-mass</th>\n",
       "      <th>systolic-blood-pressure</th>\n",
       "      <th>total-body-water</th>\n",
       "      <th>skin-temperature</th>\n",
       "      <th>blood-pressure</th>\n",
       "      <th>body-water</th>\n",
       "      <th>pulse</th>\n",
       "      <th>weight</th>\n",
       "      <th>body-temperature-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.1250</td>\n",
       "      <td>47.5853</td>\n",
       "      <td>136.4271</td>\n",
       "      <td>49.8206</td>\n",
       "      <td>34.2843</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.1250</td>\n",
       "      <td>47.5853</td>\n",
       "      <td>136.4271</td>\n",
       "      <td>49.8206</td>\n",
       "      <td>34.2843</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>64.5000</td>\n",
       "      <td>165.0000</td>\n",
       "      <td>50.6000</td>\n",
       "      <td>34.2843</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.1250</td>\n",
       "      <td>47.5853</td>\n",
       "      <td>136.4271</td>\n",
       "      <td>49.8206</td>\n",
       "      <td>34.2843</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0469</td>\n",
       "      <td>48.6600</td>\n",
       "      <td>130.7188</td>\n",
       "      <td>51.7600</td>\n",
       "      <td>34.5600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>10785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0469</td>\n",
       "      <td>48.6600</td>\n",
       "      <td>130.7188</td>\n",
       "      <td>51.7600</td>\n",
       "      <td>34.5600</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>10786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0469</td>\n",
       "      <td>48.6600</td>\n",
       "      <td>130.7188</td>\n",
       "      <td>51.7600</td>\n",
       "      <td>34.5600</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>10787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.3526</td>\n",
       "      <td>46.2964</td>\n",
       "      <td>134.0000</td>\n",
       "      <td>51.1929</td>\n",
       "      <td>34.6478</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>10788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.3526</td>\n",
       "      <td>46.2964</td>\n",
       "      <td>134.0000</td>\n",
       "      <td>51.1929</td>\n",
       "      <td>34.6478</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>10789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.3526</td>\n",
       "      <td>46.2964</td>\n",
       "      <td>134.0000</td>\n",
       "      <td>51.1929</td>\n",
       "      <td>34.6478</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10790 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  back-door  bathroom  bedroom  fridge-door  front-door  \\\n",
       "0               0        0.0       0.0      0.0          0.0         0.0   \n",
       "1               1        0.0       0.0      0.0          0.0         0.0   \n",
       "2               2       12.0       5.0     18.0         23.0        27.0   \n",
       "3               3        2.0       2.0      6.0          0.0         1.0   \n",
       "4               4        0.0       0.0      3.0          0.0         0.0   \n",
       "...           ...        ...       ...      ...          ...         ...   \n",
       "10785       10785        0.0      10.0     19.0         17.0         9.0   \n",
       "10786       10786        0.0      13.0     16.0          3.0         3.0   \n",
       "10787       10787        0.0       0.0      0.0          0.0         0.0   \n",
       "10788       10788        0.0      13.0     34.0          5.0         8.0   \n",
       "10789       10789        0.0       3.0     29.0          3.0         4.0   \n",
       "\n",
       "       hallway  kitchen  lounge  total-events  ...  heart-rate  muscle-mass  \\\n",
       "0          0.0      0.0     0.0           0.0  ...     72.1250      47.5853   \n",
       "1          0.0      0.0     0.0           0.0  ...     72.1250      47.5853   \n",
       "2         30.0     57.0    49.0         221.0  ...     42.0000      64.5000   \n",
       "3         10.0     49.0    31.0         101.0  ...     72.1250      47.5853   \n",
       "4          0.0      0.0     0.0           3.0  ...     76.0469      48.6600   \n",
       "...        ...      ...     ...           ...  ...         ...          ...   \n",
       "10785     25.0     56.0    46.0         182.0  ...     76.0469      48.6600   \n",
       "10786     23.0     22.0    34.0         114.0  ...     76.0469      48.6600   \n",
       "10787      0.0      0.0     0.0           0.0  ...     70.3526      46.2964   \n",
       "10788     17.0     38.0    31.0         146.0  ...     70.3526      46.2964   \n",
       "10789      6.0     50.0    32.0         127.0  ...     70.3526      46.2964   \n",
       "\n",
       "       systolic-blood-pressure  total-body-water  skin-temperature  \\\n",
       "0                     136.4271           49.8206           34.2843   \n",
       "1                     136.4271           49.8206           34.2843   \n",
       "2                     165.0000           50.6000           34.2843   \n",
       "3                     136.4271           49.8206           34.2843   \n",
       "4                     130.7188           51.7600           34.5600   \n",
       "...                        ...               ...               ...   \n",
       "10785                 130.7188           51.7600           34.5600   \n",
       "10786                 130.7188           51.7600           34.5600   \n",
       "10787                 134.0000           51.1929           34.6478   \n",
       "10788                 134.0000           51.1929           34.6478   \n",
       "10789                 134.0000           51.1929           34.6478   \n",
       "\n",
       "       blood-pressure  body-water   pulse  weight  body-temperature-label  \n",
       "0              0.0000      0.0000  0.0000  0.0000                     0.0  \n",
       "1              0.0000      0.0000  0.0000  0.0000                     0.0  \n",
       "2              1.0000      0.0000  1.0000  0.0000                     0.0  \n",
       "3              0.0000      0.0000  0.0000  0.0000                     0.0  \n",
       "4              0.0000      0.0000  0.0000  0.0000                     0.0  \n",
       "...               ...         ...     ...     ...                     ...  \n",
       "10785          0.1562      0.0312  0.1875  0.0312                     0.0  \n",
       "10786          0.1562      0.0312  0.1875  0.0312                     0.0  \n",
       "10787          0.1111      0.0000  0.2222  0.0000                     0.0  \n",
       "10788          0.1111      0.0000  0.2222  0.0000                     0.0  \n",
       "10789          0.1111      0.0000  0.2222  0.0000                     0.0  \n",
       "\n",
       "[10790 rows x 62 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv(os.path.join(root, 'dataset_06h_imputed.csv'))\n",
    "# y = np.load('dataset_06h_y.npy')\n",
    "\n",
    "dataset = dataset[dataset.columns]\n",
    "x = np.array(dataset)\n",
    "\n",
    "print(y.shape)\n",
    "print(x.shape)\n",
    "print(np.unique(y))\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LightGBM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m Y_TRUES = \u001b[43mnp\u001b[49m.empty([\u001b[32m0\u001b[39m])\n\u001b[32m      4\u001b[39m Y_PROBS = []\n\u001b[32m      5\u001b[39m Y_PREDS = np.empty([\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = []\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "# cv = LeavePGroupsOut(n_groups=1)\n",
    "# for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "    participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    params = {\n",
    "        'verbose': -1,  # 👈 turn off training output\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,  # Specify number of classes\n",
    "        'metric': 'multi_logloss',  # or 'auc' if you prefer\n",
    "        'num_leaves': 64,\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 100,\n",
    "        'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "        # 'scale_pos_weight': scale_pos_weight\n",
    "    }\n",
    "    bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS.append(y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics (multiclass)\n",
    "auc_roc_macro = roc_auc_score(Y_TRUES, Y_PROBS, multi_class='ovr', average='macro')\n",
    "auc_roc_weighted = roc_auc_score(Y_TRUES, Y_PROBS, multi_class='ovr', average='weighted')\n",
    "\n",
    "auc_pr_macro = average_precision_score(Y_TRUES, Y_PROBS, average='macro')\n",
    "auc_pr_weighted = average_precision_score(Y_TRUES, Y_PROBS, average='weighted')\n",
    "\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC (macro):     {auc_roc_macro:.4f}\")\n",
    "print(f\"AUC-ROC (weighted):  {auc_roc_weighted:.4f}\")\n",
    "print(f\"AUC-PR  (macro):     {auc_pr_macro:.4f}\")\n",
    "print(f\"AUC-PR  (weighted):  {auc_pr_weighted:.4f}\")\n",
    "print(f\"Accuracy:            {acc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "1 10617 173\n",
      "2 10488 302\n",
      "3 10599 191\n",
      "4 10604 186\n",
      "5 10767 23\n",
      "6 10437 353\n",
      "7 10541 249\n",
      "8 10500 290\n",
      "9 10611 179\n",
      "10 10771 19\n",
      "11 10560 230\n",
      "12 10532 258\n",
      "13 10716 74\n",
      "14 10524 266\n",
      "15 10548 242\n",
      "16 10665 125\n",
      "17 10508 282\n",
      "18 10668 122\n",
      "19 10570 220\n",
      "20 10588 202\n",
      "21 10521 269\n",
      "22 10627 163\n",
      "23 10600 190\n",
      "24 10771 19\n",
      "25 10520 270\n",
      "26 10495 295\n",
      "27 10520 270\n",
      "28 10605 185\n",
      "29 10616 174\n",
      "30 10576 214\n",
      "31 10556 234\n",
      "32 10687 103\n",
      "33 10560 230\n",
      "34 10625 165\n",
      "35 10751 39\n",
      "36 10525 265\n",
      "37 10436 354\n",
      "38 10621 169\n",
      "39 10463 327\n",
      "40 10524 266\n",
      "41 10584 206\n",
      "42 10632 158\n",
      "43 10520 270\n",
      "44 10728 62\n",
      "45 10699 91\n",
      "46 10763 27\n",
      "47 10580 210\n",
      "48 10672 118\n",
      "49 10528 262\n",
      "50 10627 163\n",
      "51 10541 249\n",
      "52 10502 288\n",
      "53 10575 215\n",
      "54 10532 258\n",
      "55 10775 15\n",
      "AUC-ROC:    0.9730\n",
      "AUC-PR:     0.3946\n",
      "Accuracy:   0.9873\n",
      "Precision:  0.4750\n",
      "Recall:     0.1407\n",
      "F1 Score:   0.2171\n",
      "Sensitivity (Recall): 0.1407\n",
      "Specificity:          0.9980\n",
      "[[10634    21]\n",
      " [  116    19]]\n"
     ]
    }
   ],
   "source": [
    "# Transformer\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    model = TabPFNClassifier(\n",
    "        device='cuda',\n",
    "        random_state=seed,\n",
    "        n_estimators = 4,\n",
    "        ignore_pretraining_limits=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS = np.append(Y_PROBS, y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "auc_roc = roc_auc_score(Y_TRUES, Y_PROBS)\n",
    "precision, recall, _ = precision_recall_curve(Y_TRUES, Y_PROBS)\n",
    "auc_pr = auc(recall, precision)\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "pre = precision_score(Y_TRUES, Y_PREDS)\n",
    "rec = recall_score(Y_TRUES, Y_PREDS)\n",
    "f1 = f1_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix: [ [TN, FP], [FN, TP] ]\n",
    "tn, fp, fn, tp = confusion_matrix(Y_TRUES, Y_PREDS).ravel()\n",
    "\n",
    "# Sensitivity = Recall = TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:     {auc_pr:.4f}\")\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"Precision:  {pre:.4f}\")\n",
    "print(f\"Recall:     {rec:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity:          {specificity:.4f}\")\n",
    "print(confusion_matrix(Y_TRUES, Y_PREDS))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(Y_TRUES, 'o', color='blue', alpha=.25, markersize=8, label='Ground-truth')\n",
    "# plt.plot(Y_PREDS, 'o', color='red', alpha=.25, markersize=8, label='Prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "1 10617 173\n",
      "2 10488 302\n",
      "3 10599 191\n",
      "4 10604 186\n",
      "5 10767 23\n",
      "6 10437 353\n",
      "7 10541 249\n",
      "8 10500 290\n",
      "9 10611 179\n",
      "10 10771 19\n",
      "11 10560 230\n",
      "12 10532 258\n",
      "13 10716 74\n",
      "14 10524 266\n",
      "15 10548 242\n",
      "16 10665 125\n",
      "17 10508 282\n",
      "18 10668 122\n",
      "19 10570 220\n",
      "20 10588 202\n",
      "21 10521 269\n",
      "22 10627 163\n",
      "23 10600 190\n",
      "24 10771 19\n",
      "25 10520 270\n",
      "26 10495 295\n",
      "27 10520 270\n",
      "28 10605 185\n",
      "29 10616 174\n",
      "30 10576 214\n",
      "31 10556 234\n",
      "32 10687 103\n",
      "33 10560 230\n",
      "34 10625 165\n",
      "35 10751 39\n",
      "36 10525 265\n",
      "37 10436 354\n",
      "38 10621 169\n",
      "39 10463 327\n",
      "40 10524 266\n",
      "41 10584 206\n",
      "42 10632 158\n",
      "43 10520 270\n",
      "44 10728 62\n",
      "45 10699 91\n",
      "46 10763 27\n",
      "47 10580 210\n",
      "48 10672 118\n",
      "49 10528 262\n",
      "50 10627 163\n",
      "51 10541 249\n",
      "52 10502 288\n",
      "53 10575 215\n",
      "54 10532 258\n",
      "55 10775 15\n",
      "AUC-ROC (macro):     0.8537\n",
      "AUC-ROC (weighted):  0.9276\n",
      "AUC-PR  (macro):     0.3110\n",
      "AUC-PR  (weighted):  0.9790\n",
      "Accuracy:            0.8948\n",
      "Confusion Matrix:\n",
      "[[9552  189  803   22]\n",
      " [  27   56   21   13]\n",
      " [  19   17   43   10]\n",
      " [   0    9    5    4]]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = []\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=100,  # match LightGBM\n",
    "        learning_rate=0.001,  # match LightGBM\n",
    "        max_depth=4,  # similar to LightGBM default tree depth\n",
    "        subsample=1.0,  # default\n",
    "        random_state=seed\n",
    "    )\n",
    "    # model.fit(x_train, y_train)\n",
    "    model.fit(x_train, y_train, sample_weight=compute_sample_weight(class_weight='balanced', y=y_train))\n",
    "    y_probs = model.predict_proba(x_test)\n",
    "    \n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS.append(y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics (multiclass)\n",
    "auc_roc_macro = roc_auc_score(Y_TRUES, Y_PROBS, multi_class='ovr', average='macro')\n",
    "auc_roc_weighted = roc_auc_score(Y_TRUES, Y_PROBS, multi_class='ovr', average='weighted')\n",
    "\n",
    "auc_pr_macro = average_precision_score(Y_TRUES, Y_PROBS, average='macro')\n",
    "auc_pr_weighted = average_precision_score(Y_TRUES, Y_PROBS, average='weighted')\n",
    "\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC (macro):     {auc_roc_macro:.4f}\")\n",
    "print(f\"AUC-ROC (weighted):  {auc_roc_weighted:.4f}\")\n",
    "print(f\"AUC-PR  (macro):     {auc_pr_macro:.4f}\")\n",
    "print(f\"AUC-PR  (weighted):  {auc_pr_weighted:.4f}\")\n",
    "print(f\"Accuracy:            {acc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "1 10617 173\n",
      "2 10488 302\n",
      "3 10599 191\n",
      "4 10604 186\n",
      "5 10767 23\n",
      "6 10437 353\n",
      "7 10541 249\n",
      "8 10500 290\n",
      "9 10611 179\n",
      "10 10771 19\n",
      "11 10560 230\n",
      "12 10532 258\n",
      "13 10716 74\n",
      "14 10524 266\n",
      "15 10548 242\n",
      "16 10665 125\n",
      "17 10508 282\n",
      "18 10668 122\n",
      "19 10570 220\n",
      "20 10588 202\n",
      "21 10521 269\n",
      "22 10627 163\n",
      "23 10600 190\n",
      "24 10771 19\n",
      "25 10520 270\n",
      "26 10495 295\n",
      "27 10520 270\n",
      "28 10605 185\n",
      "29 10616 174\n",
      "30 10576 214\n",
      "31 10556 234\n",
      "32 10687 103\n",
      "33 10560 230\n",
      "34 10625 165\n",
      "35 10751 39\n",
      "36 10525 265\n",
      "37 10436 354\n",
      "38 10621 169\n",
      "39 10463 327\n",
      "40 10524 266\n",
      "41 10584 206\n",
      "42 10632 158\n",
      "43 10520 270\n",
      "44 10728 62\n",
      "45 10699 91\n",
      "46 10763 27\n",
      "47 10580 210\n",
      "48 10672 118\n",
      "49 10528 262\n",
      "50 10627 163\n",
      "51 10541 249\n",
      "52 10502 288\n",
      "53 10575 215\n",
      "54 10532 258\n",
      "55 10775 15\n",
      "AUC-ROC:    0.9690\n",
      "AUC-PR:     0.3928\n",
      "Accuracy:   0.9876\n",
      "Precision:  0.5065\n",
      "Recall:     0.2889\n",
      "F1 Score:   0.3679\n",
      "Sensitivity (Recall): 0.2889\n",
      "Specificity:          0.9964\n",
      "[[10617    38]\n",
      " [   96    39]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=100,  # match LightGBM\n",
    "    #     learning_rate=0.001,  # match LightGBM\n",
    "    #     max_depth=4,  # similar to LightGBM default tree depth\n",
    "    #     subsample=1.0,  # default\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "\n",
    "    # ----- XGBoost\n",
    "    model = XGBClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS = np.append(Y_PROBS, y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "auc_roc = roc_auc_score(Y_TRUES, Y_PROBS)\n",
    "precision, recall, _ = precision_recall_curve(Y_TRUES, Y_PROBS)\n",
    "auc_pr = auc(recall, precision)\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "pre = precision_score(Y_TRUES, Y_PREDS)\n",
    "rec = recall_score(Y_TRUES, Y_PREDS)\n",
    "f1 = f1_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix: [ [TN, FP], [FN, TP] ]\n",
    "tn, fp, fn, tp = confusion_matrix(Y_TRUES, Y_PREDS).ravel()\n",
    "\n",
    "# Sensitivity = Recall = TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:     {auc_pr:.4f}\")\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"Precision:  {pre:.4f}\")\n",
    "print(f\"Recall:     {rec:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity:          {specificity:.4f}\")\n",
    "print(confusion_matrix(Y_TRUES, Y_PREDS))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(Y_TRUES, 'o', color='blue', alpha=.25, markersize=8, label='Ground-truth')\n",
    "# plt.plot(Y_PREDS, 'o', color='red', alpha=.25, markersize=8, label='Prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "1 10617 173\n",
      "2 10488 302\n",
      "3 10599 191\n",
      "4 10604 186\n",
      "5 10767 23\n",
      "6 10437 353\n",
      "7 10541 249\n",
      "8 10500 290\n",
      "9 10611 179\n",
      "10 10771 19\n",
      "11 10560 230\n",
      "12 10532 258\n",
      "13 10716 74\n",
      "14 10524 266\n",
      "15 10548 242\n",
      "16 10665 125\n",
      "17 10508 282\n",
      "18 10668 122\n",
      "19 10570 220\n",
      "20 10588 202\n",
      "21 10521 269\n",
      "22 10627 163\n",
      "23 10600 190\n",
      "24 10771 19\n",
      "25 10520 270\n",
      "26 10495 295\n",
      "27 10520 270\n",
      "28 10605 185\n",
      "29 10616 174\n",
      "30 10576 214\n",
      "31 10556 234\n",
      "32 10687 103\n",
      "33 10560 230\n",
      "34 10625 165\n",
      "35 10751 39\n",
      "36 10525 265\n",
      "37 10436 354\n",
      "38 10621 169\n",
      "39 10463 327\n",
      "40 10524 266\n",
      "41 10584 206\n",
      "42 10632 158\n",
      "43 10520 270\n",
      "44 10728 62\n",
      "45 10699 91\n",
      "46 10763 27\n",
      "47 10580 210\n",
      "48 10672 118\n",
      "49 10528 262\n",
      "50 10627 163\n",
      "51 10541 249\n",
      "52 10502 288\n",
      "53 10575 215\n",
      "54 10532 258\n",
      "55 10775 15\n",
      "AUC-ROC:    0.9270\n",
      "AUC-PR:     0.3763\n",
      "Accuracy:   0.9878\n",
      "Precision:  0.5652\n",
      "Recall:     0.0963\n",
      "F1 Score:   0.1646\n",
      "Sensitivity (Recall): 0.0963\n",
      "Specificity:          0.9991\n",
      "[[10645    10]\n",
      " [  122    13]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=100,  # match LightGBM\n",
    "    #     learning_rate=0.001,  # match LightGBM\n",
    "    #     max_depth=4,  # similar to LightGBM default tree depth\n",
    "    #     subsample=1.0,  # default\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "\n",
    "    # ----- XGBoost\n",
    "    # model = XGBClassifier()\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Random Forest\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=250,  # number of trees\n",
    "        max_depth=None,  # let the trees grow fully\n",
    "        random_state=seed\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS = np.append(Y_PROBS, y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "auc_roc = roc_auc_score(Y_TRUES, Y_PROBS)\n",
    "precision, recall, _ = precision_recall_curve(Y_TRUES, Y_PROBS)\n",
    "auc_pr = auc(recall, precision)\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "pre = precision_score(Y_TRUES, Y_PREDS)\n",
    "rec = recall_score(Y_TRUES, Y_PREDS)\n",
    "f1 = f1_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix: [ [TN, FP], [FN, TP] ]\n",
    "tn, fp, fn, tp = confusion_matrix(Y_TRUES, Y_PREDS).ravel()\n",
    "\n",
    "# Sensitivity = Recall = TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:     {auc_pr:.4f}\")\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"Precision:  {pre:.4f}\")\n",
    "print(f\"Recall:     {rec:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity:          {specificity:.4f}\")\n",
    "print(confusion_matrix(Y_TRUES, Y_PREDS))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(Y_TRUES, 'o', color='blue', alpha=.25, markersize=8, label='Ground-truth')\n",
    "# plt.plot(Y_PREDS, 'o', color='red', alpha=.25, markersize=8, label='Prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "1 10617 173\n",
      "2 10488 302\n",
      "3 10599 191\n",
      "4 10604 186\n",
      "5 10767 23\n",
      "6 10437 353\n",
      "7 10541 249\n",
      "8 10500 290\n",
      "9 10611 179\n",
      "10 10771 19\n",
      "11 10560 230\n",
      "12 10532 258\n",
      "13 10716 74\n",
      "14 10524 266\n",
      "15 10548 242\n",
      "16 10665 125\n",
      "17 10508 282\n",
      "18 10668 122\n",
      "19 10570 220\n",
      "20 10588 202\n",
      "21 10521 269\n",
      "22 10627 163\n",
      "23 10600 190\n",
      "24 10771 19\n",
      "25 10520 270\n",
      "26 10495 295\n",
      "27 10520 270\n",
      "28 10605 185\n",
      "29 10616 174\n",
      "30 10576 214\n",
      "31 10556 234\n",
      "32 10687 103\n",
      "33 10560 230\n",
      "34 10625 165\n",
      "35 10751 39\n",
      "36 10525 265\n",
      "37 10436 354\n",
      "38 10621 169\n",
      "39 10463 327\n",
      "40 10524 266\n",
      "41 10584 206\n",
      "42 10632 158\n",
      "43 10520 270\n",
      "44 10728 62\n",
      "45 10699 91\n",
      "46 10763 27\n",
      "47 10580 210\n",
      "48 10672 118\n",
      "49 10528 262\n",
      "50 10627 163\n",
      "51 10541 249\n",
      "52 10502 288\n",
      "53 10575 215\n",
      "54 10532 258\n",
      "55 10775 15\n",
      "AUC-ROC:    0.8021\n",
      "AUC-PR:     0.1697\n",
      "Accuracy:   0.9860\n",
      "Precision:  0.2143\n",
      "Recall:     0.0444\n",
      "F1 Score:   0.0736\n",
      "Sensitivity (Recall): 0.0444\n",
      "Specificity:          0.9979\n",
      "[[10633    22]\n",
      " [  129     6]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=100,  # match LightGBM\n",
    "    #     learning_rate=0.001,  # match LightGBM\n",
    "    #     max_depth=4,  # similar to LightGBM default tree depth\n",
    "    #     subsample=1.0,  # default\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "\n",
    "    # ----- XGBoost\n",
    "    # model = XGBClassifier()\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Random Forest\n",
    "    # model = RandomForestClassifier(\n",
    "    #     n_estimators=250,  # number of trees\n",
    "    #     max_depth=None,  # let the trees grow fully\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- SVM\n",
    "    model = SVC(kernel='rbf', probability=True, random_state=seed)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS = np.append(Y_PROBS, y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "auc_roc = roc_auc_score(Y_TRUES, Y_PROBS)\n",
    "precision, recall, _ = precision_recall_curve(Y_TRUES, Y_PROBS)\n",
    "auc_pr = auc(recall, precision)\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "pre = precision_score(Y_TRUES, Y_PREDS)\n",
    "rec = recall_score(Y_TRUES, Y_PREDS)\n",
    "f1 = f1_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix: [ [TN, FP], [FN, TP] ]\n",
    "tn, fp, fn, tp = confusion_matrix(Y_TRUES, Y_PREDS).ravel()\n",
    "\n",
    "# Sensitivity = Recall = TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:     {auc_pr:.4f}\")\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"Precision:  {pre:.4f}\")\n",
    "print(f\"Recall:     {rec:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity:          {specificity:.4f}\")\n",
    "print(confusion_matrix(Y_TRUES, Y_PREDS))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(Y_TRUES, 'o', color='blue', alpha=.25, markersize=8, label='Ground-truth')\n",
    "# plt.plot(Y_PREDS, 'o', color='red', alpha=.25, markersize=8, label='Prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "1 10617 173\n",
      "2 10488 302\n",
      "3 10599 191\n",
      "4 10604 186\n",
      "5 10767 23\n",
      "6 10437 353\n",
      "7 10541 249\n",
      "8 10500 290\n",
      "9 10611 179\n",
      "10 10771 19\n",
      "11 10560 230\n",
      "12 10532 258\n",
      "13 10716 74\n",
      "14 10524 266\n",
      "15 10548 242\n",
      "16 10665 125\n",
      "17 10508 282\n",
      "18 10668 122\n",
      "19 10570 220\n",
      "20 10588 202\n",
      "21 10521 269\n",
      "22 10627 163\n",
      "23 10600 190\n",
      "24 10771 19\n",
      "25 10520 270\n",
      "26 10495 295\n",
      "27 10520 270\n",
      "28 10605 185\n",
      "29 10616 174\n",
      "30 10576 214\n",
      "31 10556 234\n",
      "32 10687 103\n",
      "33 10560 230\n",
      "34 10625 165\n",
      "35 10751 39\n",
      "36 10525 265\n",
      "37 10436 354\n",
      "38 10621 169\n",
      "39 10463 327\n",
      "40 10524 266\n",
      "41 10584 206\n",
      "42 10632 158\n",
      "43 10520 270\n",
      "44 10728 62\n",
      "45 10699 91\n",
      "46 10763 27\n",
      "47 10580 210\n",
      "48 10672 118\n",
      "49 10528 262\n",
      "50 10627 163\n",
      "51 10541 249\n",
      "52 10502 288\n",
      "53 10575 215\n",
      "54 10532 258\n",
      "55 10775 15\n",
      "AUC-ROC:    0.6371\n",
      "AUC-PR:     0.3090\n",
      "Accuracy:   0.9838\n",
      "Precision:  0.3276\n",
      "Recall:     0.2815\n",
      "F1 Score:   0.3028\n",
      "Sensitivity (Recall): 0.2815\n",
      "Specificity:          0.9927\n",
      "[[10577    78]\n",
      " [   97    38]]\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=100,  # match LightGBM\n",
    "    #     learning_rate=0.001,  # match LightGBM\n",
    "    #     max_depth=4,  # similar to LightGBM default tree depth\n",
    "    #     subsample=1.0,  # default\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "\n",
    "    # ----- XGBoost\n",
    "    # model = XGBClassifier()\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Random Forest\n",
    "    # model = RandomForestClassifier(\n",
    "    #     n_estimators=250,  # number of trees\n",
    "    #     max_depth=None,  # let the trees grow fully\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- SVM\n",
    "    # model = SVC(kernel='rbf', probability=True, random_state=seed)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- DT\n",
    "    model = DecisionTreeClassifier(criterion=\"log_loss\", max_depth=512, random_state=seed)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_probs = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS = np.append(Y_PROBS, y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "auc_roc = roc_auc_score(Y_TRUES, Y_PROBS)\n",
    "precision, recall, _ = precision_recall_curve(Y_TRUES, Y_PROBS)\n",
    "auc_pr = auc(recall, precision)\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "pre = precision_score(Y_TRUES, Y_PREDS)\n",
    "rec = recall_score(Y_TRUES, Y_PREDS)\n",
    "f1 = f1_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix: [ [TN, FP], [FN, TP] ]\n",
    "tn, fp, fn, tp = confusion_matrix(Y_TRUES, Y_PREDS).ravel()\n",
    "\n",
    "# Sensitivity = Recall = TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:     {auc_pr:.4f}\")\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"Precision:  {pre:.4f}\")\n",
    "print(f\"Recall:     {rec:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity:          {specificity:.4f}\")\n",
    "print(confusion_matrix(Y_TRUES, Y_PREDS))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(Y_TRUES, 'o', color='blue', alpha=.25, markersize=8, label='Ground-truth')\n",
    "# plt.plot(Y_PREDS, 'o', color='red', alpha=.25, markersize=8, label='Prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "Iteration 1, loss = 0.22359075\n",
      "Validation score: 0.987013\n",
      "Iteration 2, loss = 0.07409667\n",
      "Validation score: 0.987013\n",
      "Iteration 3, loss = 0.05419803\n",
      "Validation score: 0.987013\n",
      "Iteration 4, loss = 0.04736082\n",
      "Validation score: 0.987013\n",
      "Iteration 5, loss = 0.04526200\n",
      "Validation score: 0.987013\n",
      "Iteration 6, loss = 0.04457983\n",
      "Validation score: 0.987013\n",
      "Iteration 7, loss = 0.04392281\n",
      "Validation score: 0.987013\n",
      "Iteration 8, loss = 0.04302360\n",
      "Validation score: 0.987013\n",
      "Iteration 9, loss = 0.04293123\n",
      "Validation score: 0.987013\n",
      "Iteration 10, loss = 0.04338872\n",
      "Validation score: 0.987013\n",
      "Iteration 11, loss = 0.04240246\n",
      "Validation score: 0.987013\n",
      "Iteration 12, loss = 0.04298408\n",
      "Validation score: 0.987013\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "1 10617 173\n",
      "Iteration 1, loss = 0.22521033\n",
      "Validation score: 0.987759\n",
      "Iteration 2, loss = 0.07557132\n",
      "Validation score: 0.987759\n",
      "Iteration 3, loss = 0.05631219\n",
      "Validation score: 0.987759\n",
      "Iteration 4, loss = 0.04912314\n",
      "Validation score: 0.987759\n",
      "Iteration 5, loss = 0.04646625\n",
      "Validation score: 0.986817\n",
      "Iteration 6, loss = 0.04610225\n",
      "Validation score: 0.987759\n",
      "Iteration 7, loss = 0.04595231\n",
      "Validation score: 0.986817\n",
      "Iteration 8, loss = 0.04520345\n",
      "Validation score: 0.985876\n",
      "Iteration 9, loss = 0.04474785\n",
      "Validation score: 0.985876\n",
      "Iteration 10, loss = 0.04427101\n",
      "Validation score: 0.987759\n",
      "Iteration 11, loss = 0.04417197\n",
      "Validation score: 0.986817\n",
      "Iteration 12, loss = 0.04397762\n",
      "Validation score: 0.985876\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "2 10488 302\n",
      "Iteration 1, loss = 0.22767101\n",
      "Validation score: 0.987607\n",
      "Iteration 2, loss = 0.07794769\n",
      "Validation score: 0.987607\n",
      "Iteration 3, loss = 0.05698580\n",
      "Validation score: 0.987607\n",
      "Iteration 4, loss = 0.04864520\n",
      "Validation score: 0.987607\n",
      "Iteration 5, loss = 0.04610000\n",
      "Validation score: 0.987607\n",
      "Iteration 6, loss = 0.04549393\n",
      "Validation score: 0.987607\n",
      "Iteration 7, loss = 0.04428578\n",
      "Validation score: 0.987607\n",
      "Iteration 8, loss = 0.04406085\n",
      "Validation score: 0.987607\n",
      "Iteration 9, loss = 0.04354513\n",
      "Validation score: 0.987607\n",
      "Iteration 10, loss = 0.04269821\n",
      "Validation score: 0.987607\n",
      "Iteration 11, loss = 0.04169664\n",
      "Validation score: 0.987607\n",
      "Iteration 12, loss = 0.04197791\n",
      "Validation score: 0.987607\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "3 10599 191\n",
      "Iteration 1, loss = 0.21973647\n",
      "Validation score: 0.988679\n",
      "Iteration 2, loss = 0.07291508\n",
      "Validation score: 0.988679\n",
      "Iteration 3, loss = 0.05376950\n",
      "Validation score: 0.988679\n",
      "Iteration 4, loss = 0.04639793\n",
      "Validation score: 0.988679\n",
      "Iteration 5, loss = 0.04387640\n",
      "Validation score: 0.988679\n",
      "Iteration 6, loss = 0.04234230\n",
      "Validation score: 0.988679\n",
      "Iteration 7, loss = 0.04211487\n",
      "Validation score: 0.988679\n",
      "Iteration 8, loss = 0.04081208\n",
      "Validation score: 0.988679\n",
      "Iteration 9, loss = 0.04103377\n",
      "Validation score: 0.988679\n",
      "Iteration 10, loss = 0.04018621\n",
      "Validation score: 0.989623\n",
      "Iteration 11, loss = 0.03960046\n",
      "Validation score: 0.988679\n",
      "Iteration 12, loss = 0.03934185\n",
      "Validation score: 0.988679\n",
      "Iteration 13, loss = 0.03829209\n",
      "Validation score: 0.989623\n",
      "Iteration 14, loss = 0.03757386\n",
      "Validation score: 0.989623\n",
      "Iteration 15, loss = 0.03814896\n",
      "Validation score: 0.989623\n",
      "Iteration 16, loss = 0.03733012\n",
      "Validation score: 0.989623\n",
      "Iteration 17, loss = 0.03656965\n",
      "Validation score: 0.988679\n",
      "Iteration 18, loss = 0.03836407\n",
      "Validation score: 0.986792\n",
      "Iteration 19, loss = 0.03623860\n",
      "Validation score: 0.987736\n",
      "Iteration 20, loss = 0.03517358\n",
      "Validation score: 0.988679\n",
      "Iteration 21, loss = 0.03482838\n",
      "Validation score: 0.988679\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "4 10604 186\n",
      "Iteration 1, loss = 0.22732756\n",
      "Validation score: 0.986805\n",
      "Iteration 2, loss = 0.07517352\n",
      "Validation score: 0.986805\n",
      "Iteration 3, loss = 0.05584503\n",
      "Validation score: 0.986805\n",
      "Iteration 4, loss = 0.04814469\n",
      "Validation score: 0.986805\n",
      "Iteration 5, loss = 0.04559324\n",
      "Validation score: 0.986805\n",
      "Iteration 6, loss = 0.04460278\n",
      "Validation score: 0.986805\n",
      "Iteration 7, loss = 0.04462732\n",
      "Validation score: 0.986805\n",
      "Iteration 8, loss = 0.04422507\n",
      "Validation score: 0.986805\n",
      "Iteration 9, loss = 0.04378327\n",
      "Validation score: 0.986805\n",
      "Iteration 10, loss = 0.04413176\n",
      "Validation score: 0.986805\n",
      "Iteration 11, loss = 0.04289775\n",
      "Validation score: 0.986805\n",
      "Iteration 12, loss = 0.04262200\n",
      "Validation score: 0.986805\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "5 10767 23\n",
      "Iteration 1, loss = 0.22423582\n",
      "Validation score: 0.987001\n",
      "Iteration 2, loss = 0.07504788\n",
      "Validation score: 0.987001\n",
      "Iteration 3, loss = 0.05425307\n",
      "Validation score: 0.987001\n",
      "Iteration 4, loss = 0.04627552\n",
      "Validation score: 0.987001\n",
      "Iteration 5, loss = 0.04392320\n",
      "Validation score: 0.987001\n",
      "Iteration 6, loss = 0.04332134\n",
      "Validation score: 0.987001\n",
      "Iteration 7, loss = 0.04275266\n",
      "Validation score: 0.987001\n",
      "Iteration 8, loss = 0.04211012\n",
      "Validation score: 0.987001\n",
      "Iteration 9, loss = 0.04230859\n",
      "Validation score: 0.987001\n",
      "Iteration 10, loss = 0.04146595\n",
      "Validation score: 0.987001\n",
      "Iteration 11, loss = 0.04087312\n",
      "Validation score: 0.987001\n",
      "Iteration 12, loss = 0.04023743\n",
      "Validation score: 0.987001\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "6 10437 353\n",
      "Iteration 1, loss = 0.22736745\n",
      "Validation score: 0.988506\n",
      "Iteration 2, loss = 0.07537860\n",
      "Validation score: 0.988506\n",
      "Iteration 3, loss = 0.05667522\n",
      "Validation score: 0.988506\n",
      "Iteration 4, loss = 0.04873113\n",
      "Validation score: 0.988506\n",
      "Iteration 5, loss = 0.04523755\n",
      "Validation score: 0.988506\n",
      "Iteration 6, loss = 0.04403088\n",
      "Validation score: 0.988506\n",
      "Iteration 7, loss = 0.04332334\n",
      "Validation score: 0.988506\n",
      "Iteration 8, loss = 0.04271226\n",
      "Validation score: 0.988506\n",
      "Iteration 9, loss = 0.04289318\n",
      "Validation score: 0.988506\n",
      "Iteration 10, loss = 0.04279593\n",
      "Validation score: 0.988506\n",
      "Iteration 11, loss = 0.04243196\n",
      "Validation score: 0.988506\n",
      "Iteration 12, loss = 0.04191760\n",
      "Validation score: 0.988506\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "7 10541 249\n",
      "Iteration 1, loss = 0.22758350\n",
      "Validation score: 0.986730\n",
      "Iteration 2, loss = 0.07633266\n",
      "Validation score: 0.986730\n",
      "Iteration 3, loss = 0.05610391\n",
      "Validation score: 0.986730\n",
      "Iteration 4, loss = 0.04813329\n",
      "Validation score: 0.986730\n",
      "Iteration 5, loss = 0.04569774\n",
      "Validation score: 0.986730\n",
      "Iteration 6, loss = 0.04508539\n",
      "Validation score: 0.986730\n",
      "Iteration 7, loss = 0.04429032\n",
      "Validation score: 0.985782\n",
      "Iteration 8, loss = 0.04477019\n",
      "Validation score: 0.986730\n",
      "Iteration 9, loss = 0.04343999\n",
      "Validation score: 0.986730\n",
      "Iteration 10, loss = 0.04388769\n",
      "Validation score: 0.986730\n",
      "Iteration 11, loss = 0.04305474\n",
      "Validation score: 0.986730\n",
      "Iteration 12, loss = 0.04292283\n",
      "Validation score: 0.986730\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "8 10500 290\n",
      "Iteration 1, loss = 0.22750268\n",
      "Validation score: 0.987619\n",
      "Iteration 2, loss = 0.07597311\n",
      "Validation score: 0.987619\n",
      "Iteration 3, loss = 0.05649674\n",
      "Validation score: 0.987619\n",
      "Iteration 4, loss = 0.04887120\n",
      "Validation score: 0.987619\n",
      "Iteration 5, loss = 0.04680428\n",
      "Validation score: 0.987619\n",
      "Iteration 6, loss = 0.04614134\n",
      "Validation score: 0.987619\n",
      "Iteration 7, loss = 0.04527605\n",
      "Validation score: 0.987619\n",
      "Iteration 8, loss = 0.04493385\n",
      "Validation score: 0.987619\n",
      "Iteration 9, loss = 0.04421926\n",
      "Validation score: 0.987619\n",
      "Iteration 10, loss = 0.04430609\n",
      "Validation score: 0.987619\n",
      "Iteration 11, loss = 0.04495155\n",
      "Validation score: 0.987619\n",
      "Iteration 12, loss = 0.04342119\n",
      "Validation score: 0.985714\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "9 10611 179\n",
      "Iteration 1, loss = 0.22105502\n",
      "Validation score: 0.986817\n",
      "Iteration 2, loss = 0.07939670\n",
      "Validation score: 0.986817\n",
      "Iteration 3, loss = 0.05770629\n",
      "Validation score: 0.986817\n",
      "Iteration 4, loss = 0.04973892\n",
      "Validation score: 0.986817\n",
      "Iteration 5, loss = 0.04663444\n",
      "Validation score: 0.986817\n",
      "Iteration 6, loss = 0.04556260\n",
      "Validation score: 0.986817\n",
      "Iteration 7, loss = 0.04475968\n",
      "Validation score: 0.986817\n",
      "Iteration 8, loss = 0.04418943\n",
      "Validation score: 0.986817\n",
      "Iteration 9, loss = 0.04479965\n",
      "Validation score: 0.986817\n",
      "Iteration 10, loss = 0.04363103\n",
      "Validation score: 0.986817\n",
      "Iteration 11, loss = 0.04319035\n",
      "Validation score: 0.986817\n",
      "Iteration 12, loss = 0.04274353\n",
      "Validation score: 0.986817\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "10 10771 19\n",
      "Iteration 1, loss = 0.22361785\n",
      "Validation score: 0.987013\n",
      "Iteration 2, loss = 0.07482025\n",
      "Validation score: 0.987013\n",
      "Iteration 3, loss = 0.05239670\n",
      "Validation score: 0.987013\n",
      "Iteration 4, loss = 0.04589728\n",
      "Validation score: 0.987013\n",
      "Iteration 5, loss = 0.04517565\n",
      "Validation score: 0.987013\n",
      "Iteration 6, loss = 0.04327339\n",
      "Validation score: 0.987013\n",
      "Iteration 7, loss = 0.04243470\n",
      "Validation score: 0.987013\n",
      "Iteration 8, loss = 0.04170586\n",
      "Validation score: 0.987013\n",
      "Iteration 9, loss = 0.04110979\n",
      "Validation score: 0.987013\n",
      "Iteration 10, loss = 0.04104477\n",
      "Validation score: 0.987013\n",
      "Iteration 11, loss = 0.04017662\n",
      "Validation score: 0.987941\n",
      "Iteration 12, loss = 0.04106442\n",
      "Validation score: 0.987941\n",
      "Iteration 13, loss = 0.03959727\n",
      "Validation score: 0.987941\n",
      "Iteration 14, loss = 0.03891511\n",
      "Validation score: 0.987013\n",
      "Iteration 15, loss = 0.03831343\n",
      "Validation score: 0.987013\n",
      "Iteration 16, loss = 0.03966018\n",
      "Validation score: 0.987941\n",
      "Iteration 17, loss = 0.03835055\n",
      "Validation score: 0.987941\n",
      "Iteration 18, loss = 0.03806664\n",
      "Validation score: 0.987941\n",
      "Iteration 19, loss = 0.03711388\n",
      "Validation score: 0.987013\n",
      "Iteration 20, loss = 0.03757105\n",
      "Validation score: 0.987941\n",
      "Iteration 21, loss = 0.03680492\n",
      "Validation score: 0.986085\n",
      "Iteration 22, loss = 0.03662702\n",
      "Validation score: 0.987941\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "11 10560 230\n",
      "Iteration 1, loss = 0.22761937\n",
      "Validation score: 0.987689\n",
      "Iteration 2, loss = 0.07662942\n",
      "Validation score: 0.987689\n",
      "Iteration 3, loss = 0.05745223\n",
      "Validation score: 0.987689\n",
      "Iteration 4, loss = 0.04909300\n",
      "Validation score: 0.987689\n",
      "Iteration 5, loss = 0.04697268\n",
      "Validation score: 0.987689\n",
      "Iteration 6, loss = 0.04586719\n",
      "Validation score: 0.987689\n",
      "Iteration 7, loss = 0.04641238\n",
      "Validation score: 0.987689\n",
      "Iteration 8, loss = 0.04448851\n",
      "Validation score: 0.987689\n",
      "Iteration 9, loss = 0.04437289\n",
      "Validation score: 0.987689\n",
      "Iteration 10, loss = 0.04384232\n",
      "Validation score: 0.987689\n",
      "Iteration 11, loss = 0.04283637\n",
      "Validation score: 0.987689\n",
      "Iteration 12, loss = 0.04286693\n",
      "Validation score: 0.987689\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "12 10532 258\n",
      "Iteration 1, loss = 0.22466861\n",
      "Validation score: 0.986717\n",
      "Iteration 2, loss = 0.07642667\n",
      "Validation score: 0.986717\n",
      "Iteration 3, loss = 0.05641585\n",
      "Validation score: 0.986717\n",
      "Iteration 4, loss = 0.04906229\n",
      "Validation score: 0.986717\n",
      "Iteration 5, loss = 0.04679432\n",
      "Validation score: 0.986717\n",
      "Iteration 6, loss = 0.04660970\n",
      "Validation score: 0.986717\n",
      "Iteration 7, loss = 0.04581858\n",
      "Validation score: 0.986717\n",
      "Iteration 8, loss = 0.04582857\n",
      "Validation score: 0.986717\n",
      "Iteration 9, loss = 0.04468776\n",
      "Validation score: 0.986717\n",
      "Iteration 10, loss = 0.04513833\n",
      "Validation score: 0.986717\n",
      "Iteration 11, loss = 0.04404519\n",
      "Validation score: 0.986717\n",
      "Iteration 12, loss = 0.04388895\n",
      "Validation score: 0.986717\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "13 10716 74\n",
      "Iteration 1, loss = 0.23018223\n",
      "Validation score: 0.986940\n",
      "Iteration 2, loss = 0.07446841\n",
      "Validation score: 0.986940\n",
      "Iteration 3, loss = 0.05592164\n",
      "Validation score: 0.986940\n",
      "Iteration 4, loss = 0.04821509\n",
      "Validation score: 0.986940\n",
      "Iteration 5, loss = 0.04626422\n",
      "Validation score: 0.986940\n",
      "Iteration 6, loss = 0.04564010\n",
      "Validation score: 0.986940\n",
      "Iteration 7, loss = 0.04443268\n",
      "Validation score: 0.986940\n",
      "Iteration 8, loss = 0.04474760\n",
      "Validation score: 0.986940\n",
      "Iteration 9, loss = 0.04341990\n",
      "Validation score: 0.986940\n",
      "Iteration 10, loss = 0.04282511\n",
      "Validation score: 0.986940\n",
      "Iteration 11, loss = 0.04322894\n",
      "Validation score: 0.986940\n",
      "Iteration 12, loss = 0.04214138\n",
      "Validation score: 0.986940\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "14 10524 266\n",
      "Iteration 1, loss = 0.23284413\n",
      "Validation score: 0.987654\n",
      "Iteration 2, loss = 0.07736409\n",
      "Validation score: 0.987654\n",
      "Iteration 3, loss = 0.05773053\n",
      "Validation score: 0.987654\n",
      "Iteration 4, loss = 0.04982059\n",
      "Validation score: 0.987654\n",
      "Iteration 5, loss = 0.04703655\n",
      "Validation score: 0.987654\n",
      "Iteration 6, loss = 0.04642111\n",
      "Validation score: 0.987654\n",
      "Iteration 7, loss = 0.04627558\n",
      "Validation score: 0.987654\n",
      "Iteration 8, loss = 0.04523459\n",
      "Validation score: 0.987654\n",
      "Iteration 9, loss = 0.04438599\n",
      "Validation score: 0.987654\n",
      "Iteration 10, loss = 0.04450727\n",
      "Validation score: 0.987654\n",
      "Iteration 11, loss = 0.04537667\n",
      "Validation score: 0.987654\n",
      "Iteration 12, loss = 0.04375558\n",
      "Validation score: 0.987654\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "15 10548 242\n",
      "Iteration 1, loss = 0.23180316\n",
      "Validation score: 0.987678\n",
      "Iteration 2, loss = 0.07936943\n",
      "Validation score: 0.987678\n",
      "Iteration 3, loss = 0.05643508\n",
      "Validation score: 0.987678\n",
      "Iteration 4, loss = 0.04903093\n",
      "Validation score: 0.987678\n",
      "Iteration 5, loss = 0.04627390\n",
      "Validation score: 0.987678\n",
      "Iteration 6, loss = 0.04558087\n",
      "Validation score: 0.987678\n",
      "Iteration 7, loss = 0.04557528\n",
      "Validation score: 0.987678\n",
      "Iteration 8, loss = 0.04453410\n",
      "Validation score: 0.987678\n",
      "Iteration 9, loss = 0.04448003\n",
      "Validation score: 0.987678\n",
      "Iteration 10, loss = 0.04445249\n",
      "Validation score: 0.987678\n",
      "Iteration 11, loss = 0.04354752\n",
      "Validation score: 0.987678\n",
      "Iteration 12, loss = 0.04335381\n",
      "Validation score: 0.987678\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "16 10665 125\n",
      "Iteration 1, loss = 0.22934638\n",
      "Validation score: 0.987816\n",
      "Iteration 2, loss = 0.07559412\n",
      "Validation score: 0.987816\n",
      "Iteration 3, loss = 0.05669433\n",
      "Validation score: 0.987816\n",
      "Iteration 4, loss = 0.05007770\n",
      "Validation score: 0.987816\n",
      "Iteration 5, loss = 0.04693170\n",
      "Validation score: 0.987816\n",
      "Iteration 6, loss = 0.04578626\n",
      "Validation score: 0.987816\n",
      "Iteration 7, loss = 0.04557961\n",
      "Validation score: 0.987816\n",
      "Iteration 8, loss = 0.04484440\n",
      "Validation score: 0.987816\n",
      "Iteration 9, loss = 0.04464717\n",
      "Validation score: 0.987816\n",
      "Iteration 10, loss = 0.04521251\n",
      "Validation score: 0.987816\n",
      "Iteration 11, loss = 0.04375268\n",
      "Validation score: 0.987816\n",
      "Iteration 12, loss = 0.04324400\n",
      "Validation score: 0.987816\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "17 10508 282\n",
      "Iteration 1, loss = 0.22748731\n",
      "Validation score: 0.986679\n",
      "Iteration 2, loss = 0.07778573\n",
      "Validation score: 0.986679\n",
      "Iteration 3, loss = 0.05671729\n",
      "Validation score: 0.986679\n",
      "Iteration 4, loss = 0.04905350\n",
      "Validation score: 0.986679\n",
      "Iteration 5, loss = 0.04706439\n",
      "Validation score: 0.986679\n",
      "Iteration 6, loss = 0.04585826\n",
      "Validation score: 0.986679\n",
      "Iteration 7, loss = 0.04536436\n",
      "Validation score: 0.986679\n",
      "Iteration 8, loss = 0.04474110\n",
      "Validation score: 0.986679\n",
      "Iteration 9, loss = 0.04527511\n",
      "Validation score: 0.986679\n",
      "Iteration 10, loss = 0.04442644\n",
      "Validation score: 0.986679\n",
      "Iteration 11, loss = 0.04481285\n",
      "Validation score: 0.986679\n",
      "Iteration 12, loss = 0.04389519\n",
      "Validation score: 0.986679\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "18 10668 122\n",
      "Iteration 1, loss = 0.22274644\n",
      "Validation score: 0.986879\n",
      "Iteration 2, loss = 0.07856502\n",
      "Validation score: 0.986879\n",
      "Iteration 3, loss = 0.05774853\n",
      "Validation score: 0.986879\n",
      "Iteration 4, loss = 0.04899176\n",
      "Validation score: 0.986879\n",
      "Iteration 5, loss = 0.04747618\n",
      "Validation score: 0.986879\n",
      "Iteration 6, loss = 0.04683448\n",
      "Validation score: 0.986879\n",
      "Iteration 7, loss = 0.04580912\n",
      "Validation score: 0.986879\n",
      "Iteration 8, loss = 0.04483784\n",
      "Validation score: 0.986879\n",
      "Iteration 9, loss = 0.04416348\n",
      "Validation score: 0.986879\n",
      "Iteration 10, loss = 0.04383391\n",
      "Validation score: 0.986879\n",
      "Iteration 11, loss = 0.04354727\n",
      "Validation score: 0.986879\n",
      "Iteration 12, loss = 0.04354537\n",
      "Validation score: 0.986879\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "19 10570 220\n",
      "Iteration 1, loss = 0.22552498\n",
      "Validation score: 0.987701\n",
      "Iteration 2, loss = 0.07496857\n",
      "Validation score: 0.987701\n",
      "Iteration 3, loss = 0.05527252\n",
      "Validation score: 0.987701\n",
      "Iteration 4, loss = 0.04827744\n",
      "Validation score: 0.987701\n",
      "Iteration 5, loss = 0.04666705\n",
      "Validation score: 0.986755\n",
      "Iteration 6, loss = 0.04627871\n",
      "Validation score: 0.987701\n",
      "Iteration 7, loss = 0.04511566\n",
      "Validation score: 0.986755\n",
      "Iteration 8, loss = 0.04496885\n",
      "Validation score: 0.987701\n",
      "Iteration 9, loss = 0.04365089\n",
      "Validation score: 0.987701\n",
      "Iteration 10, loss = 0.04332962\n",
      "Validation score: 0.987701\n",
      "Iteration 11, loss = 0.04332922\n",
      "Validation score: 0.985809\n",
      "Iteration 12, loss = 0.04216070\n",
      "Validation score: 0.987701\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "20 10588 202\n",
      "Iteration 1, loss = 0.22627007\n",
      "Validation score: 0.986780\n",
      "Iteration 2, loss = 0.07500231\n",
      "Validation score: 0.986780\n",
      "Iteration 3, loss = 0.05817346\n",
      "Validation score: 0.986780\n",
      "Iteration 4, loss = 0.05082528\n",
      "Validation score: 0.986780\n",
      "Iteration 5, loss = 0.04849028\n",
      "Validation score: 0.986780\n",
      "Iteration 6, loss = 0.04688378\n",
      "Validation score: 0.986780\n",
      "Iteration 7, loss = 0.04643508\n",
      "Validation score: 0.986780\n",
      "Iteration 8, loss = 0.04594092\n",
      "Validation score: 0.986780\n",
      "Iteration 9, loss = 0.04586012\n",
      "Validation score: 0.986780\n",
      "Iteration 10, loss = 0.04476964\n",
      "Validation score: 0.986780\n",
      "Iteration 11, loss = 0.04462922\n",
      "Validation score: 0.986780\n",
      "Iteration 12, loss = 0.04381544\n",
      "Validation score: 0.986780\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "21 10521 269\n",
      "Iteration 1, loss = 0.22741828\n",
      "Validation score: 0.987654\n",
      "Iteration 2, loss = 0.07790387\n",
      "Validation score: 0.987654\n",
      "Iteration 3, loss = 0.05739359\n",
      "Validation score: 0.987654\n",
      "Iteration 4, loss = 0.04844085\n",
      "Validation score: 0.987654\n",
      "Iteration 5, loss = 0.04642357\n",
      "Validation score: 0.987654\n",
      "Iteration 6, loss = 0.04781641\n",
      "Validation score: 0.987654\n",
      "Iteration 7, loss = 0.04443787\n",
      "Validation score: 0.987654\n",
      "Iteration 8, loss = 0.04401646\n",
      "Validation score: 0.987654\n",
      "Iteration 9, loss = 0.04378196\n",
      "Validation score: 0.987654\n",
      "Iteration 10, loss = 0.04327659\n",
      "Validation score: 0.987654\n",
      "Iteration 11, loss = 0.04312580\n",
      "Validation score: 0.987654\n",
      "Iteration 12, loss = 0.04244276\n",
      "Validation score: 0.987654\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "22 10627 163\n",
      "Iteration 1, loss = 0.22631478\n",
      "Validation score: 0.986830\n",
      "Iteration 2, loss = 0.07534627\n",
      "Validation score: 0.986830\n",
      "Iteration 3, loss = 0.05399475\n",
      "Validation score: 0.986830\n",
      "Iteration 4, loss = 0.04717724\n",
      "Validation score: 0.986830\n",
      "Iteration 5, loss = 0.04567835\n",
      "Validation score: 0.986830\n",
      "Iteration 6, loss = 0.04424774\n",
      "Validation score: 0.986830\n",
      "Iteration 7, loss = 0.04574133\n",
      "Validation score: 0.985889\n",
      "Iteration 8, loss = 0.04358883\n",
      "Validation score: 0.984948\n",
      "Iteration 9, loss = 0.04335730\n",
      "Validation score: 0.985889\n",
      "Iteration 10, loss = 0.04366024\n",
      "Validation score: 0.982126\n",
      "Iteration 11, loss = 0.04345333\n",
      "Validation score: 0.985889\n",
      "Iteration 12, loss = 0.04235941\n",
      "Validation score: 0.985889\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "23 10600 190\n",
      "Iteration 1, loss = 0.21948461\n",
      "Validation score: 0.990566\n",
      "Iteration 2, loss = 0.06348599\n",
      "Validation score: 0.990566\n",
      "Iteration 3, loss = 0.04703253\n",
      "Validation score: 0.990566\n",
      "Iteration 4, loss = 0.03856717\n",
      "Validation score: 0.990566\n",
      "Iteration 5, loss = 0.03545072\n",
      "Validation score: 0.990566\n",
      "Iteration 6, loss = 0.03456923\n",
      "Validation score: 0.990566\n",
      "Iteration 7, loss = 0.03311498\n",
      "Validation score: 0.990566\n",
      "Iteration 8, loss = 0.03328244\n",
      "Validation score: 0.990566\n",
      "Iteration 9, loss = 0.03268783\n",
      "Validation score: 0.990566\n",
      "Iteration 10, loss = 0.03258719\n",
      "Validation score: 0.990566\n",
      "Iteration 11, loss = 0.03189965\n",
      "Validation score: 0.990566\n",
      "Iteration 12, loss = 0.03210697\n",
      "Validation score: 0.991509\n",
      "Iteration 13, loss = 0.03146525\n",
      "Validation score: 0.990566\n",
      "Iteration 14, loss = 0.03164070\n",
      "Validation score: 0.990566\n",
      "Iteration 15, loss = 0.03112760\n",
      "Validation score: 0.990566\n",
      "Iteration 16, loss = 0.03136757\n",
      "Validation score: 0.990566\n",
      "Iteration 17, loss = 0.03024876\n",
      "Validation score: 0.990566\n",
      "Iteration 18, loss = 0.03045857\n",
      "Validation score: 0.990566\n",
      "Iteration 19, loss = 0.02997758\n",
      "Validation score: 0.990566\n",
      "Iteration 20, loss = 0.02962099\n",
      "Validation score: 0.990566\n",
      "Iteration 21, loss = 0.02930700\n",
      "Validation score: 0.990566\n",
      "Iteration 22, loss = 0.02959074\n",
      "Validation score: 0.990566\n",
      "Iteration 23, loss = 0.02929198\n",
      "Validation score: 0.990566\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "24 10771 19\n",
      "Iteration 1, loss = 0.22385204\n",
      "Validation score: 0.987013\n",
      "Iteration 2, loss = 0.07469063\n",
      "Validation score: 0.987013\n",
      "Iteration 3, loss = 0.05391718\n",
      "Validation score: 0.987013\n",
      "Iteration 4, loss = 0.04638681\n",
      "Validation score: 0.987013\n",
      "Iteration 5, loss = 0.04519073\n",
      "Validation score: 0.987013\n",
      "Iteration 6, loss = 0.04351634\n",
      "Validation score: 0.987013\n",
      "Iteration 7, loss = 0.04256739\n",
      "Validation score: 0.987013\n",
      "Iteration 8, loss = 0.04192275\n",
      "Validation score: 0.987013\n",
      "Iteration 9, loss = 0.04144970\n",
      "Validation score: 0.987013\n",
      "Iteration 10, loss = 0.04131678\n",
      "Validation score: 0.987013\n",
      "Iteration 11, loss = 0.04050652\n",
      "Validation score: 0.987941\n",
      "Iteration 12, loss = 0.04108071\n",
      "Validation score: 0.987013\n",
      "Iteration 13, loss = 0.04007661\n",
      "Validation score: 0.987941\n",
      "Iteration 14, loss = 0.03922356\n",
      "Validation score: 0.987013\n",
      "Iteration 15, loss = 0.03856917\n",
      "Validation score: 0.987013\n",
      "Iteration 16, loss = 0.03959853\n",
      "Validation score: 0.987941\n",
      "Iteration 17, loss = 0.03860704\n",
      "Validation score: 0.987013\n",
      "Iteration 18, loss = 0.03823933\n",
      "Validation score: 0.987941\n",
      "Iteration 19, loss = 0.03715081\n",
      "Validation score: 0.987013\n",
      "Iteration 20, loss = 0.03775047\n",
      "Validation score: 0.987013\n",
      "Iteration 21, loss = 0.03702009\n",
      "Validation score: 0.984230\n",
      "Iteration 22, loss = 0.03668051\n",
      "Validation score: 0.987013\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "25 10520 270\n",
      "Iteration 1, loss = 0.22829587\n",
      "Validation score: 0.987643\n",
      "Iteration 2, loss = 0.07253802\n",
      "Validation score: 0.987643\n",
      "Iteration 3, loss = 0.05501251\n",
      "Validation score: 0.987643\n",
      "Iteration 4, loss = 0.04830663\n",
      "Validation score: 0.987643\n",
      "Iteration 5, loss = 0.04581111\n",
      "Validation score: 0.987643\n",
      "Iteration 6, loss = 0.04537064\n",
      "Validation score: 0.987643\n",
      "Iteration 7, loss = 0.04568087\n",
      "Validation score: 0.987643\n",
      "Iteration 8, loss = 0.04444826\n",
      "Validation score: 0.987643\n",
      "Iteration 9, loss = 0.04415843\n",
      "Validation score: 0.987643\n",
      "Iteration 10, loss = 0.04324453\n",
      "Validation score: 0.987643\n",
      "Iteration 11, loss = 0.04322114\n",
      "Validation score: 0.987643\n",
      "Iteration 12, loss = 0.04306793\n",
      "Validation score: 0.987643\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "26 10495 295\n",
      "Iteration 1, loss = 0.22256417\n",
      "Validation score: 0.987619\n",
      "Iteration 2, loss = 0.07823694\n",
      "Validation score: 0.987619\n",
      "Iteration 3, loss = 0.05748707\n",
      "Validation score: 0.987619\n",
      "Iteration 4, loss = 0.04891734\n",
      "Validation score: 0.987619\n",
      "Iteration 5, loss = 0.04705074\n",
      "Validation score: 0.987619\n",
      "Iteration 6, loss = 0.04547070\n",
      "Validation score: 0.987619\n",
      "Iteration 7, loss = 0.04538610\n",
      "Validation score: 0.987619\n",
      "Iteration 8, loss = 0.04510744\n",
      "Validation score: 0.987619\n",
      "Iteration 9, loss = 0.04461279\n",
      "Validation score: 0.987619\n",
      "Iteration 10, loss = 0.04442189\n",
      "Validation score: 0.987619\n",
      "Iteration 11, loss = 0.04342583\n",
      "Validation score: 0.987619\n",
      "Iteration 12, loss = 0.04330432\n",
      "Validation score: 0.987619\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "27 10520 270\n",
      "Iteration 1, loss = 0.22708186\n",
      "Validation score: 0.987643\n",
      "Iteration 2, loss = 0.07810856\n",
      "Validation score: 0.987643\n",
      "Iteration 3, loss = 0.05868057\n",
      "Validation score: 0.987643\n",
      "Iteration 4, loss = 0.04996469\n",
      "Validation score: 0.987643\n",
      "Iteration 5, loss = 0.04771166\n",
      "Validation score: 0.987643\n",
      "Iteration 6, loss = 0.04909188\n",
      "Validation score: 0.987643\n",
      "Iteration 7, loss = 0.04584249\n",
      "Validation score: 0.987643\n",
      "Iteration 8, loss = 0.04545432\n",
      "Validation score: 0.987643\n",
      "Iteration 9, loss = 0.04461397\n",
      "Validation score: 0.987643\n",
      "Iteration 10, loss = 0.04452225\n",
      "Validation score: 0.987643\n",
      "Iteration 11, loss = 0.04432689\n",
      "Validation score: 0.987643\n",
      "Iteration 12, loss = 0.04384958\n",
      "Validation score: 0.987643\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "28 10605 185\n",
      "Iteration 1, loss = 0.22636121\n",
      "Validation score: 0.988690\n",
      "Iteration 2, loss = 0.07199567\n",
      "Validation score: 0.988690\n",
      "Iteration 3, loss = 0.05385939\n",
      "Validation score: 0.988690\n",
      "Iteration 4, loss = 0.04646291\n",
      "Validation score: 0.988690\n",
      "Iteration 5, loss = 0.04357438\n",
      "Validation score: 0.988690\n",
      "Iteration 6, loss = 0.04393831\n",
      "Validation score: 0.988690\n",
      "Iteration 7, loss = 0.04195474\n",
      "Validation score: 0.988690\n",
      "Iteration 8, loss = 0.04228522\n",
      "Validation score: 0.988690\n",
      "Iteration 9, loss = 0.04130980\n",
      "Validation score: 0.988690\n",
      "Iteration 10, loss = 0.04048886\n",
      "Validation score: 0.988690\n",
      "Iteration 11, loss = 0.04076782\n",
      "Validation score: 0.988690\n",
      "Iteration 12, loss = 0.04032485\n",
      "Validation score: 0.988690\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "29 10616 174\n",
      "Iteration 1, loss = 0.22782415\n",
      "Validation score: 0.987759\n",
      "Iteration 2, loss = 0.07569070\n",
      "Validation score: 0.987759\n",
      "Iteration 3, loss = 0.05622919\n",
      "Validation score: 0.987759\n",
      "Iteration 4, loss = 0.04835769\n",
      "Validation score: 0.987759\n",
      "Iteration 5, loss = 0.04495331\n",
      "Validation score: 0.987759\n",
      "Iteration 6, loss = 0.04512870\n",
      "Validation score: 0.987759\n",
      "Iteration 7, loss = 0.04449435\n",
      "Validation score: 0.987759\n",
      "Iteration 8, loss = 0.04345135\n",
      "Validation score: 0.987759\n",
      "Iteration 9, loss = 0.04312681\n",
      "Validation score: 0.987759\n",
      "Iteration 10, loss = 0.04245060\n",
      "Validation score: 0.987759\n",
      "Iteration 11, loss = 0.04312899\n",
      "Validation score: 0.987759\n",
      "Iteration 12, loss = 0.04183041\n",
      "Validation score: 0.987759\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "30 10576 214\n",
      "Iteration 1, loss = 0.23009099\n",
      "Validation score: 0.987713\n",
      "Iteration 2, loss = 0.07742843\n",
      "Validation score: 0.987713\n",
      "Iteration 3, loss = 0.05744550\n",
      "Validation score: 0.987713\n",
      "Iteration 4, loss = 0.04941936\n",
      "Validation score: 0.987713\n",
      "Iteration 5, loss = 0.04645300\n",
      "Validation score: 0.987713\n",
      "Iteration 6, loss = 0.04561417\n",
      "Validation score: 0.987713\n",
      "Iteration 7, loss = 0.04481961\n",
      "Validation score: 0.987713\n",
      "Iteration 8, loss = 0.04425175\n",
      "Validation score: 0.987713\n",
      "Iteration 9, loss = 0.04470928\n",
      "Validation score: 0.987713\n",
      "Iteration 10, loss = 0.04411266\n",
      "Validation score: 0.987713\n",
      "Iteration 11, loss = 0.04307763\n",
      "Validation score: 0.987713\n",
      "Iteration 12, loss = 0.04267200\n",
      "Validation score: 0.987713\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "31 10556 234\n",
      "Iteration 1, loss = 0.23165452\n",
      "Validation score: 0.987689\n",
      "Iteration 2, loss = 0.07264441\n",
      "Validation score: 0.987689\n",
      "Iteration 3, loss = 0.05372795\n",
      "Validation score: 0.987689\n",
      "Iteration 4, loss = 0.04715079\n",
      "Validation score: 0.987689\n",
      "Iteration 5, loss = 0.04492531\n",
      "Validation score: 0.987689\n",
      "Iteration 6, loss = 0.04501456\n",
      "Validation score: 0.987689\n",
      "Iteration 7, loss = 0.04421988\n",
      "Validation score: 0.987689\n",
      "Iteration 8, loss = 0.04352736\n",
      "Validation score: 0.987689\n",
      "Iteration 9, loss = 0.04311541\n",
      "Validation score: 0.987689\n",
      "Iteration 10, loss = 0.04286758\n",
      "Validation score: 0.986742\n",
      "Iteration 11, loss = 0.04195719\n",
      "Validation score: 0.987689\n",
      "Iteration 12, loss = 0.04178305\n",
      "Validation score: 0.987689\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "32 10687 103\n",
      "Iteration 1, loss = 0.22626099\n",
      "Validation score: 0.986904\n",
      "Iteration 2, loss = 0.07690988\n",
      "Validation score: 0.986904\n",
      "Iteration 3, loss = 0.05707438\n",
      "Validation score: 0.986904\n",
      "Iteration 4, loss = 0.04934173\n",
      "Validation score: 0.986904\n",
      "Iteration 5, loss = 0.04617280\n",
      "Validation score: 0.986904\n",
      "Iteration 6, loss = 0.04513129\n",
      "Validation score: 0.986904\n",
      "Iteration 7, loss = 0.04499653\n",
      "Validation score: 0.986904\n",
      "Iteration 8, loss = 0.04381080\n",
      "Validation score: 0.986904\n",
      "Iteration 9, loss = 0.04475582\n",
      "Validation score: 0.986904\n",
      "Iteration 10, loss = 0.04266497\n",
      "Validation score: 0.986904\n",
      "Iteration 11, loss = 0.04318436\n",
      "Validation score: 0.986904\n",
      "Iteration 12, loss = 0.04226293\n",
      "Validation score: 0.987839\n",
      "Iteration 13, loss = 0.04179380\n",
      "Validation score: 0.986904\n",
      "Iteration 14, loss = 0.04194919\n",
      "Validation score: 0.986904\n",
      "Iteration 15, loss = 0.04077791\n",
      "Validation score: 0.986904\n",
      "Iteration 16, loss = 0.04034420\n",
      "Validation score: 0.986904\n",
      "Iteration 17, loss = 0.04072564\n",
      "Validation score: 0.986904\n",
      "Iteration 18, loss = 0.04017811\n",
      "Validation score: 0.987839\n",
      "Iteration 19, loss = 0.03972285\n",
      "Validation score: 0.986904\n",
      "Iteration 20, loss = 0.03868802\n",
      "Validation score: 0.985968\n",
      "Iteration 21, loss = 0.03839607\n",
      "Validation score: 0.986904\n",
      "Iteration 22, loss = 0.03905750\n",
      "Validation score: 0.986904\n",
      "Iteration 23, loss = 0.03787891\n",
      "Validation score: 0.986904\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "33 10560 230\n",
      "Iteration 1, loss = 0.22775767\n",
      "Validation score: 0.987689\n",
      "Iteration 2, loss = 0.07669730\n",
      "Validation score: 0.987689\n",
      "Iteration 3, loss = 0.05646582\n",
      "Validation score: 0.987689\n",
      "Iteration 4, loss = 0.04832148\n",
      "Validation score: 0.987689\n",
      "Iteration 5, loss = 0.04684374\n",
      "Validation score: 0.987689\n",
      "Iteration 6, loss = 0.04571477\n",
      "Validation score: 0.987689\n",
      "Iteration 7, loss = 0.04611279\n",
      "Validation score: 0.987689\n",
      "Iteration 8, loss = 0.04448315\n",
      "Validation score: 0.987689\n",
      "Iteration 9, loss = 0.04428658\n",
      "Validation score: 0.987689\n",
      "Iteration 10, loss = 0.04369143\n",
      "Validation score: 0.987689\n",
      "Iteration 11, loss = 0.04305567\n",
      "Validation score: 0.987689\n",
      "Iteration 12, loss = 0.04313682\n",
      "Validation score: 0.987689\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "34 10625 165\n",
      "Iteration 1, loss = 0.22675372\n",
      "Validation score: 0.986830\n",
      "Iteration 2, loss = 0.07720642\n",
      "Validation score: 0.986830\n",
      "Iteration 3, loss = 0.05770439\n",
      "Validation score: 0.986830\n",
      "Iteration 4, loss = 0.05090362\n",
      "Validation score: 0.986830\n",
      "Iteration 5, loss = 0.04749754\n",
      "Validation score: 0.986830\n",
      "Iteration 6, loss = 0.04617658\n",
      "Validation score: 0.986830\n",
      "Iteration 7, loss = 0.04623069\n",
      "Validation score: 0.986830\n",
      "Iteration 8, loss = 0.04589447\n",
      "Validation score: 0.986830\n",
      "Iteration 9, loss = 0.04527731\n",
      "Validation score: 0.986830\n",
      "Iteration 10, loss = 0.04452512\n",
      "Validation score: 0.986830\n",
      "Iteration 11, loss = 0.04364769\n",
      "Validation score: 0.986830\n",
      "Iteration 12, loss = 0.04328283\n",
      "Validation score: 0.986830\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "35 10751 39\n",
      "Iteration 1, loss = 0.22589944\n",
      "Validation score: 0.986989\n",
      "Iteration 2, loss = 0.07370884\n",
      "Validation score: 0.986989\n",
      "Iteration 3, loss = 0.05519787\n",
      "Validation score: 0.986989\n",
      "Iteration 4, loss = 0.04851546\n",
      "Validation score: 0.986989\n",
      "Iteration 5, loss = 0.04591401\n",
      "Validation score: 0.986989\n",
      "Iteration 6, loss = 0.04509237\n",
      "Validation score: 0.986989\n",
      "Iteration 7, loss = 0.04379840\n",
      "Validation score: 0.986989\n",
      "Iteration 8, loss = 0.04342351\n",
      "Validation score: 0.986989\n",
      "Iteration 9, loss = 0.04302213\n",
      "Validation score: 0.986989\n",
      "Iteration 10, loss = 0.04219180\n",
      "Validation score: 0.986989\n",
      "Iteration 11, loss = 0.04205278\n",
      "Validation score: 0.986989\n",
      "Iteration 12, loss = 0.04248365\n",
      "Validation score: 0.986989\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "36 10525 265\n",
      "Iteration 1, loss = 0.22866577\n",
      "Validation score: 0.986705\n",
      "Iteration 2, loss = 0.07772927\n",
      "Validation score: 0.986705\n",
      "Iteration 3, loss = 0.05708880\n",
      "Validation score: 0.986705\n",
      "Iteration 4, loss = 0.05052909\n",
      "Validation score: 0.986705\n",
      "Iteration 5, loss = 0.04708751\n",
      "Validation score: 0.986705\n",
      "Iteration 6, loss = 0.04638223\n",
      "Validation score: 0.986705\n",
      "Iteration 7, loss = 0.04533237\n",
      "Validation score: 0.986705\n",
      "Iteration 8, loss = 0.04657047\n",
      "Validation score: 0.986705\n",
      "Iteration 9, loss = 0.04488982\n",
      "Validation score: 0.986705\n",
      "Iteration 10, loss = 0.04483064\n",
      "Validation score: 0.986705\n",
      "Iteration 11, loss = 0.04425180\n",
      "Validation score: 0.986705\n",
      "Iteration 12, loss = 0.04435978\n",
      "Validation score: 0.986705\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "37 10436 354\n",
      "Iteration 1, loss = 0.23277754\n",
      "Validation score: 0.987548\n",
      "Iteration 2, loss = 0.07644258\n",
      "Validation score: 0.987548\n",
      "Iteration 3, loss = 0.05669683\n",
      "Validation score: 0.987548\n",
      "Iteration 4, loss = 0.04810346\n",
      "Validation score: 0.987548\n",
      "Iteration 5, loss = 0.04647442\n",
      "Validation score: 0.987548\n",
      "Iteration 6, loss = 0.04474166\n",
      "Validation score: 0.987548\n",
      "Iteration 7, loss = 0.04507841\n",
      "Validation score: 0.987548\n",
      "Iteration 8, loss = 0.04453090\n",
      "Validation score: 0.987548\n",
      "Iteration 9, loss = 0.04337050\n",
      "Validation score: 0.987548\n",
      "Iteration 10, loss = 0.04321681\n",
      "Validation score: 0.987548\n",
      "Iteration 11, loss = 0.04258466\n",
      "Validation score: 0.987548\n",
      "Iteration 12, loss = 0.04208808\n",
      "Validation score: 0.987548\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "38 10621 169\n",
      "Iteration 1, loss = 0.22515605\n",
      "Validation score: 0.988711\n",
      "Iteration 2, loss = 0.07190095\n",
      "Validation score: 0.988711\n",
      "Iteration 3, loss = 0.05272954\n",
      "Validation score: 0.988711\n",
      "Iteration 4, loss = 0.04452344\n",
      "Validation score: 0.988711\n",
      "Iteration 5, loss = 0.04232386\n",
      "Validation score: 0.988711\n",
      "Iteration 6, loss = 0.04199123\n",
      "Validation score: 0.988711\n",
      "Iteration 7, loss = 0.04109605\n",
      "Validation score: 0.988711\n",
      "Iteration 8, loss = 0.04063080\n",
      "Validation score: 0.988711\n",
      "Iteration 9, loss = 0.04067920\n",
      "Validation score: 0.988711\n",
      "Iteration 10, loss = 0.04041122\n",
      "Validation score: 0.988711\n",
      "Iteration 11, loss = 0.03942796\n",
      "Validation score: 0.988711\n",
      "Iteration 12, loss = 0.03909319\n",
      "Validation score: 0.987770\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "39 10463 327\n",
      "Iteration 1, loss = 0.23057139\n",
      "Validation score: 0.986628\n",
      "Iteration 2, loss = 0.07809728\n",
      "Validation score: 0.986628\n",
      "Iteration 3, loss = 0.05887156\n",
      "Validation score: 0.986628\n",
      "Iteration 4, loss = 0.05135763\n",
      "Validation score: 0.986628\n",
      "Iteration 5, loss = 0.04867474\n",
      "Validation score: 0.986628\n",
      "Iteration 6, loss = 0.04733687\n",
      "Validation score: 0.986628\n",
      "Iteration 7, loss = 0.04659632\n",
      "Validation score: 0.986628\n",
      "Iteration 8, loss = 0.04790370\n",
      "Validation score: 0.986628\n",
      "Iteration 9, loss = 0.04658747\n",
      "Validation score: 0.986628\n",
      "Iteration 10, loss = 0.04529242\n",
      "Validation score: 0.986628\n",
      "Iteration 11, loss = 0.04574175\n",
      "Validation score: 0.986628\n",
      "Iteration 12, loss = 0.04601964\n",
      "Validation score: 0.986628\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "40 10524 266\n",
      "Iteration 1, loss = 0.23316528\n",
      "Validation score: 0.986705\n",
      "Iteration 2, loss = 0.07666280\n",
      "Validation score: 0.986705\n",
      "Iteration 3, loss = 0.05813396\n",
      "Validation score: 0.986705\n",
      "Iteration 4, loss = 0.04992261\n",
      "Validation score: 0.986705\n",
      "Iteration 5, loss = 0.04733174\n",
      "Validation score: 0.986705\n",
      "Iteration 6, loss = 0.04655170\n",
      "Validation score: 0.986705\n",
      "Iteration 7, loss = 0.04628204\n",
      "Validation score: 0.986705\n",
      "Iteration 8, loss = 0.04546207\n",
      "Validation score: 0.986705\n",
      "Iteration 9, loss = 0.04463535\n",
      "Validation score: 0.986705\n",
      "Iteration 10, loss = 0.04521873\n",
      "Validation score: 0.986705\n",
      "Iteration 11, loss = 0.04443087\n",
      "Validation score: 0.986705\n",
      "Iteration 12, loss = 0.04409734\n",
      "Validation score: 0.986705\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "41 10584 206\n",
      "Iteration 1, loss = 0.22999280\n",
      "Validation score: 0.986780\n",
      "Iteration 2, loss = 0.07613087\n",
      "Validation score: 0.986780\n",
      "Iteration 3, loss = 0.05716986\n",
      "Validation score: 0.986780\n",
      "Iteration 4, loss = 0.04959125\n",
      "Validation score: 0.986780\n",
      "Iteration 5, loss = 0.04809821\n",
      "Validation score: 0.986780\n",
      "Iteration 6, loss = 0.04727183\n",
      "Validation score: 0.986780\n",
      "Iteration 7, loss = 0.04649694\n",
      "Validation score: 0.986780\n",
      "Iteration 8, loss = 0.04576272\n",
      "Validation score: 0.986780\n",
      "Iteration 9, loss = 0.04596688\n",
      "Validation score: 0.986780\n",
      "Iteration 10, loss = 0.04502269\n",
      "Validation score: 0.985836\n",
      "Iteration 11, loss = 0.04499474\n",
      "Validation score: 0.986780\n",
      "Iteration 12, loss = 0.04382391\n",
      "Validation score: 0.986780\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "42 10632 158\n",
      "Iteration 1, loss = 0.22275973\n",
      "Validation score: 0.986842\n",
      "Iteration 2, loss = 0.07706377\n",
      "Validation score: 0.986842\n",
      "Iteration 3, loss = 0.05596062\n",
      "Validation score: 0.986842\n",
      "Iteration 4, loss = 0.04791520\n",
      "Validation score: 0.986842\n",
      "Iteration 5, loss = 0.04661767\n",
      "Validation score: 0.986842\n",
      "Iteration 6, loss = 0.04534071\n",
      "Validation score: 0.986842\n",
      "Iteration 7, loss = 0.04418867\n",
      "Validation score: 0.986842\n",
      "Iteration 8, loss = 0.04420100\n",
      "Validation score: 0.986842\n",
      "Iteration 9, loss = 0.04407606\n",
      "Validation score: 0.986842\n",
      "Iteration 10, loss = 0.04485185\n",
      "Validation score: 0.985902\n",
      "Iteration 11, loss = 0.04275063\n",
      "Validation score: 0.985902\n",
      "Iteration 12, loss = 0.04264862\n",
      "Validation score: 0.986842\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "43 10520 270\n",
      "Iteration 1, loss = 0.22780608\n",
      "Validation score: 0.987643\n",
      "Iteration 2, loss = 0.07780342\n",
      "Validation score: 0.987643\n",
      "Iteration 3, loss = 0.05820826\n",
      "Validation score: 0.987643\n",
      "Iteration 4, loss = 0.04953106\n",
      "Validation score: 0.987643\n",
      "Iteration 5, loss = 0.04762031\n",
      "Validation score: 0.987643\n",
      "Iteration 6, loss = 0.04869238\n",
      "Validation score: 0.987643\n",
      "Iteration 7, loss = 0.04570247\n",
      "Validation score: 0.987643\n",
      "Iteration 8, loss = 0.04509837\n",
      "Validation score: 0.987643\n",
      "Iteration 9, loss = 0.04446823\n",
      "Validation score: 0.987643\n",
      "Iteration 10, loss = 0.04438366\n",
      "Validation score: 0.987643\n",
      "Iteration 11, loss = 0.04415087\n",
      "Validation score: 0.987643\n",
      "Iteration 12, loss = 0.04389789\n",
      "Validation score: 0.987643\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "44 10728 62\n",
      "Iteration 1, loss = 0.22614627\n",
      "Validation score: 0.986952\n",
      "Iteration 2, loss = 0.07554513\n",
      "Validation score: 0.986952\n",
      "Iteration 3, loss = 0.05669429\n",
      "Validation score: 0.986952\n",
      "Iteration 4, loss = 0.04907980\n",
      "Validation score: 0.986952\n",
      "Iteration 5, loss = 0.04700382\n",
      "Validation score: 0.986952\n",
      "Iteration 6, loss = 0.04580588\n",
      "Validation score: 0.986952\n",
      "Iteration 7, loss = 0.04544679\n",
      "Validation score: 0.986952\n",
      "Iteration 8, loss = 0.04445727\n",
      "Validation score: 0.986952\n",
      "Iteration 9, loss = 0.04525502\n",
      "Validation score: 0.986952\n",
      "Iteration 10, loss = 0.04414076\n",
      "Validation score: 0.986952\n",
      "Iteration 11, loss = 0.04387545\n",
      "Validation score: 0.986952\n",
      "Iteration 12, loss = 0.04350150\n",
      "Validation score: 0.986952\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "45 10699 91\n",
      "Iteration 1, loss = 0.22360377\n",
      "Validation score: 0.987850\n",
      "Iteration 2, loss = 0.07366880\n",
      "Validation score: 0.987850\n",
      "Iteration 3, loss = 0.05447741\n",
      "Validation score: 0.987850\n",
      "Iteration 4, loss = 0.04791406\n",
      "Validation score: 0.987850\n",
      "Iteration 5, loss = 0.04551481\n",
      "Validation score: 0.987850\n",
      "Iteration 6, loss = 0.04475359\n",
      "Validation score: 0.987850\n",
      "Iteration 7, loss = 0.04449650\n",
      "Validation score: 0.986916\n",
      "Iteration 8, loss = 0.04357643\n",
      "Validation score: 0.986916\n",
      "Iteration 9, loss = 0.04366102\n",
      "Validation score: 0.987850\n",
      "Iteration 10, loss = 0.04323414\n",
      "Validation score: 0.987850\n",
      "Iteration 11, loss = 0.04212546\n",
      "Validation score: 0.985981\n",
      "Iteration 12, loss = 0.04209113\n",
      "Validation score: 0.986916\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "46 10763 27\n",
      "Iteration 1, loss = 0.22635695\n",
      "Validation score: 0.987001\n",
      "Iteration 2, loss = 0.07531592\n",
      "Validation score: 0.987001\n",
      "Iteration 3, loss = 0.05568590\n",
      "Validation score: 0.987001\n",
      "Iteration 4, loss = 0.04730363\n",
      "Validation score: 0.987001\n",
      "Iteration 5, loss = 0.04576004\n",
      "Validation score: 0.987001\n",
      "Iteration 6, loss = 0.04366956\n",
      "Validation score: 0.987001\n",
      "Iteration 7, loss = 0.04308286\n",
      "Validation score: 0.987001\n",
      "Iteration 8, loss = 0.04229773\n",
      "Validation score: 0.987001\n",
      "Iteration 9, loss = 0.04314059\n",
      "Validation score: 0.987001\n",
      "Iteration 10, loss = 0.04172612\n",
      "Validation score: 0.986072\n",
      "Iteration 11, loss = 0.04065716\n",
      "Validation score: 0.987001\n",
      "Iteration 12, loss = 0.04098351\n",
      "Validation score: 0.986072\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "47 10580 210\n",
      "Iteration 1, loss = 0.22532377\n",
      "Validation score: 0.987713\n",
      "Iteration 2, loss = 0.07552833\n",
      "Validation score: 0.987713\n",
      "Iteration 3, loss = 0.05665355\n",
      "Validation score: 0.987713\n",
      "Iteration 4, loss = 0.04914830\n",
      "Validation score: 0.987713\n",
      "Iteration 5, loss = 0.04613802\n",
      "Validation score: 0.987713\n",
      "Iteration 6, loss = 0.04519514\n",
      "Validation score: 0.987713\n",
      "Iteration 7, loss = 0.04413178\n",
      "Validation score: 0.987713\n",
      "Iteration 8, loss = 0.04359209\n",
      "Validation score: 0.987713\n",
      "Iteration 9, loss = 0.04274136\n",
      "Validation score: 0.987713\n",
      "Iteration 10, loss = 0.04286026\n",
      "Validation score: 0.987713\n",
      "Iteration 11, loss = 0.04252225\n",
      "Validation score: 0.987713\n",
      "Iteration 12, loss = 0.04185711\n",
      "Validation score: 0.987713\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "48 10672 118\n",
      "Iteration 1, loss = 0.23139363\n",
      "Validation score: 0.986891\n",
      "Iteration 2, loss = 0.07405808\n",
      "Validation score: 0.986891\n",
      "Iteration 3, loss = 0.05623900\n",
      "Validation score: 0.986891\n",
      "Iteration 4, loss = 0.04877460\n",
      "Validation score: 0.986891\n",
      "Iteration 5, loss = 0.05072293\n",
      "Validation score: 0.986891\n",
      "Iteration 6, loss = 0.04604981\n",
      "Validation score: 0.986891\n",
      "Iteration 7, loss = 0.04629024\n",
      "Validation score: 0.986891\n",
      "Iteration 8, loss = 0.04516590\n",
      "Validation score: 0.986891\n",
      "Iteration 9, loss = 0.04548985\n",
      "Validation score: 0.986891\n",
      "Iteration 10, loss = 0.04384139\n",
      "Validation score: 0.986891\n",
      "Iteration 11, loss = 0.04346701\n",
      "Validation score: 0.986891\n",
      "Iteration 12, loss = 0.04343258\n",
      "Validation score: 0.985955\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "49 10528 262\n",
      "Iteration 1, loss = 0.23043005\n",
      "Validation score: 0.987654\n",
      "Iteration 2, loss = 0.07513933\n",
      "Validation score: 0.987654\n",
      "Iteration 3, loss = 0.05641772\n",
      "Validation score: 0.987654\n",
      "Iteration 4, loss = 0.04868201\n",
      "Validation score: 0.987654\n",
      "Iteration 5, loss = 0.04601619\n",
      "Validation score: 0.987654\n",
      "Iteration 6, loss = 0.04571449\n",
      "Validation score: 0.987654\n",
      "Iteration 7, loss = 0.04421288\n",
      "Validation score: 0.987654\n",
      "Iteration 8, loss = 0.04407995\n",
      "Validation score: 0.987654\n",
      "Iteration 9, loss = 0.04373909\n",
      "Validation score: 0.987654\n",
      "Iteration 10, loss = 0.04329389\n",
      "Validation score: 0.987654\n",
      "Iteration 11, loss = 0.04418836\n",
      "Validation score: 0.987654\n",
      "Iteration 12, loss = 0.04235891\n",
      "Validation score: 0.987654\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "50 10627 163\n",
      "Iteration 1, loss = 0.22621014\n",
      "Validation score: 0.987770\n",
      "Iteration 2, loss = 0.07557292\n",
      "Validation score: 0.987770\n",
      "Iteration 3, loss = 0.05427200\n",
      "Validation score: 0.987770\n",
      "Iteration 4, loss = 0.04745902\n",
      "Validation score: 0.987770\n",
      "Iteration 5, loss = 0.04558340\n",
      "Validation score: 0.987770\n",
      "Iteration 6, loss = 0.04437592\n",
      "Validation score: 0.987770\n",
      "Iteration 7, loss = 0.04493370\n",
      "Validation score: 0.987770\n",
      "Iteration 8, loss = 0.04376559\n",
      "Validation score: 0.987770\n",
      "Iteration 9, loss = 0.04326249\n",
      "Validation score: 0.987770\n",
      "Iteration 10, loss = 0.04309072\n",
      "Validation score: 0.987770\n",
      "Iteration 11, loss = 0.04253845\n",
      "Validation score: 0.987770\n",
      "Iteration 12, loss = 0.04235874\n",
      "Validation score: 0.987770\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "51 10541 249\n",
      "Iteration 1, loss = 0.22602361\n",
      "Validation score: 0.987678\n",
      "Iteration 2, loss = 0.07331011\n",
      "Validation score: 0.987678\n",
      "Iteration 3, loss = 0.05389536\n",
      "Validation score: 0.987678\n",
      "Iteration 4, loss = 0.04686705\n",
      "Validation score: 0.987678\n",
      "Iteration 5, loss = 0.04466757\n",
      "Validation score: 0.987678\n",
      "Iteration 6, loss = 0.04374851\n",
      "Validation score: 0.987678\n",
      "Iteration 7, loss = 0.04327236\n",
      "Validation score: 0.987678\n",
      "Iteration 8, loss = 0.04288897\n",
      "Validation score: 0.987678\n",
      "Iteration 9, loss = 0.04212172\n",
      "Validation score: 0.987678\n",
      "Iteration 10, loss = 0.04246771\n",
      "Validation score: 0.987678\n",
      "Iteration 11, loss = 0.04154687\n",
      "Validation score: 0.987678\n",
      "Iteration 12, loss = 0.04136728\n",
      "Validation score: 0.987678\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "52 10502 288\n",
      "Iteration 1, loss = 0.22466551\n",
      "Validation score: 0.987631\n",
      "Iteration 2, loss = 0.07635845\n",
      "Validation score: 0.987631\n",
      "Iteration 3, loss = 0.05655209\n",
      "Validation score: 0.987631\n",
      "Iteration 4, loss = 0.04921354\n",
      "Validation score: 0.987631\n",
      "Iteration 5, loss = 0.04738717\n",
      "Validation score: 0.987631\n",
      "Iteration 6, loss = 0.04503315\n",
      "Validation score: 0.987631\n",
      "Iteration 7, loss = 0.04476074\n",
      "Validation score: 0.987631\n",
      "Iteration 8, loss = 0.04392540\n",
      "Validation score: 0.987631\n",
      "Iteration 9, loss = 0.04350958\n",
      "Validation score: 0.987631\n",
      "Iteration 10, loss = 0.04412042\n",
      "Validation score: 0.987631\n",
      "Iteration 11, loss = 0.04301106\n",
      "Validation score: 0.987631\n",
      "Iteration 12, loss = 0.04247400\n",
      "Validation score: 0.987631\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "53 10575 215\n",
      "Iteration 1, loss = 0.23098438\n",
      "Validation score: 0.987713\n",
      "Iteration 2, loss = 0.07580356\n",
      "Validation score: 0.987713\n",
      "Iteration 3, loss = 0.05719307\n",
      "Validation score: 0.987713\n",
      "Iteration 4, loss = 0.04904629\n",
      "Validation score: 0.987713\n",
      "Iteration 5, loss = 0.04688102\n",
      "Validation score: 0.987713\n",
      "Iteration 6, loss = 0.04547715\n",
      "Validation score: 0.987713\n",
      "Iteration 7, loss = 0.04701842\n",
      "Validation score: 0.987713\n",
      "Iteration 8, loss = 0.04440087\n",
      "Validation score: 0.987713\n",
      "Iteration 9, loss = 0.04440940\n",
      "Validation score: 0.987713\n",
      "Iteration 10, loss = 0.04442911\n",
      "Validation score: 0.987713\n",
      "Iteration 11, loss = 0.04296072\n",
      "Validation score: 0.987713\n",
      "Iteration 12, loss = 0.04271796\n",
      "Validation score: 0.987713\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "54 10532 258\n",
      "Iteration 1, loss = 0.22436651\n",
      "Validation score: 0.986717\n",
      "Iteration 2, loss = 0.07621532\n",
      "Validation score: 0.986717\n",
      "Iteration 3, loss = 0.05552007\n",
      "Validation score: 0.986717\n",
      "Iteration 4, loss = 0.04820371\n",
      "Validation score: 0.986717\n",
      "Iteration 5, loss = 0.04624802\n",
      "Validation score: 0.986717\n",
      "Iteration 6, loss = 0.04640225\n",
      "Validation score: 0.986717\n",
      "Iteration 7, loss = 0.04558389\n",
      "Validation score: 0.986717\n",
      "Iteration 8, loss = 0.04579690\n",
      "Validation score: 0.986717\n",
      "Iteration 9, loss = 0.04488475\n",
      "Validation score: 0.986717\n",
      "Iteration 10, loss = 0.04474166\n",
      "Validation score: 0.986717\n",
      "Iteration 11, loss = 0.04401716\n",
      "Validation score: 0.986717\n",
      "Iteration 12, loss = 0.04365114\n",
      "Validation score: 0.985769\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "55 10775 15\n",
      "Iteration 1, loss = 0.22605499\n",
      "Validation score: 0.987013\n",
      "Iteration 2, loss = 0.07422459\n",
      "Validation score: 0.987013\n",
      "Iteration 3, loss = 0.05414112\n",
      "Validation score: 0.987013\n",
      "Iteration 4, loss = 0.04597523\n",
      "Validation score: 0.987013\n",
      "Iteration 5, loss = 0.04503089\n",
      "Validation score: 0.987013\n",
      "Iteration 6, loss = 0.04319642\n",
      "Validation score: 0.987013\n",
      "Iteration 7, loss = 0.04276550\n",
      "Validation score: 0.987013\n",
      "Iteration 8, loss = 0.04179368\n",
      "Validation score: 0.987013\n",
      "Iteration 9, loss = 0.04160509\n",
      "Validation score: 0.987013\n",
      "Iteration 10, loss = 0.04113506\n",
      "Validation score: 0.987013\n",
      "Iteration 11, loss = 0.04134562\n",
      "Validation score: 0.987013\n",
      "Iteration 12, loss = 0.04089192\n",
      "Validation score: 0.985158\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "AUC-ROC:    0.3258\n",
      "AUC-PR:     0.0568\n",
      "Accuracy:   0.9872\n",
      "Precision:  0.3636\n",
      "Recall:     0.0296\n",
      "F1 Score:   0.0548\n",
      "Sensitivity (Recall): 0.0296\n",
      "Specificity:          0.9993\n",
      "[[10648     7]\n",
      " [  131     4]]\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=100,  # match LightGBM\n",
    "    #     learning_rate=0.001,  # match LightGBM\n",
    "    #     max_depth=4,  # similar to LightGBM default tree depth\n",
    "    #     subsample=1.0,  # default\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "\n",
    "    # ----- XGBoost\n",
    "    # model = XGBClassifier()\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Random Forest\n",
    "    # model = RandomForestClassifier(\n",
    "    #     n_estimators=250,  # number of trees\n",
    "    #     max_depth=None,  # let the trees grow fully\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- SVM\n",
    "    # model = SVC(kernel='rbf', probability=True, random_state=seed)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- DT\n",
    "    # model = DecisionTreeClassifier(criterion=\"log_loss\", max_depth=512, random_state=seed)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict(x_test)\n",
    "\n",
    "\n",
    "    # MLP\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),    # 2 hidden layers: 64 and 32 neurons\n",
    "        activation='relu',              # good default: 'relu'\n",
    "        solver='adam',                  # optimizer\n",
    "        alpha=0.0001,                   # L2 regularization\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        random_state=seed,\n",
    "        verbose=True,\n",
    "    )\n",
    "    model.fit(x_train, y_train)    \n",
    "    y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    y_preds = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS = np.append(Y_PROBS, y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, y_preds)\n",
    "\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "auc_roc = roc_auc_score(Y_TRUES, Y_PROBS)\n",
    "precision, recall, _ = precision_recall_curve(Y_TRUES, Y_PROBS)\n",
    "auc_pr = auc(recall, precision)\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "pre = precision_score(Y_TRUES, Y_PREDS)\n",
    "rec = recall_score(Y_TRUES, Y_PREDS)\n",
    "f1 = f1_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix: [ [TN, FP], [FN, TP] ]\n",
    "tn, fp, fn, tp = confusion_matrix(Y_TRUES, Y_PREDS).ravel()\n",
    "\n",
    "# Sensitivity = Recall = TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:     {auc_pr:.4f}\")\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"Precision:  {pre:.4f}\")\n",
    "print(f\"Recall:     {rec:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity:          {specificity:.4f}\")\n",
    "print(confusion_matrix(Y_TRUES, Y_PREDS))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(Y_TRUES, 'o', color='blue', alpha=.25, markersize=8, label='Ground-truth')\n",
    "# plt.plot(Y_PREDS, 'o', color='red', alpha=.25, markersize=8, label='Prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10779 11\n",
      "1 10617 173\n",
      "2 10488 302\n",
      "3 10599 191\n",
      "4 10604 186\n",
      "5 10767 23\n",
      "6 10437 353\n",
      "7 10541 249\n",
      "8 10500 290\n",
      "9 10611 179\n",
      "10 10771 19\n",
      "11 10560 230\n",
      "12 10532 258\n",
      "13 10716 74\n",
      "14 10524 266\n",
      "15 10548 242\n",
      "16 10665 125\n",
      "17 10508 282\n",
      "18 10668 122\n",
      "19 10570 220\n",
      "20 10588 202\n",
      "21 10521 269\n",
      "22 10627 163\n",
      "23 10600 190\n",
      "24 10771 19\n",
      "25 10520 270\n",
      "26 10495 295\n",
      "27 10520 270\n",
      "28 10605 185\n",
      "29 10616 174\n",
      "30 10576 214\n",
      "31 10556 234\n",
      "32 10687 103\n",
      "33 10560 230\n",
      "34 10625 165\n",
      "35 10751 39\n",
      "36 10525 265\n",
      "37 10436 354\n",
      "38 10621 169\n",
      "39 10463 327\n",
      "40 10524 266\n",
      "41 10584 206\n",
      "42 10632 158\n",
      "43 10520 270\n",
      "44 10728 62\n",
      "45 10699 91\n",
      "46 10763 27\n",
      "47 10580 210\n",
      "48 10672 118\n",
      "49 10528 262\n",
      "50 10627 163\n",
      "51 10541 249\n",
      "52 10502 288\n",
      "53 10575 215\n",
      "54 10532 258\n",
      "55 10775 15\n",
      "AUC-ROC:    0.8791\n",
      "AUC-PR:     0.2407\n",
      "Accuracy:   0.8862\n",
      "Precision:  0.0838\n",
      "Recall:     0.8148\n",
      "F1 Score:   0.1519\n",
      "Sensitivity (Recall): 0.8148\n",
      "Specificity:          0.8871\n",
      "[[9452 1203]\n",
      " [  25  110]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = np.empty([0])\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # Undersample class 0\n",
    "    # reduction_percent = 99\n",
    "    # print(\"Original class distribution:\", Counter(y_train))    \n",
    "    # class_0_idx = np.where(y_train == 0)[0]\n",
    "    # class_1_idx = np.where(y_train == 1)[0]\n",
    "    # # How many class 0 samples to keep\n",
    "    # n_keep = int(len(class_0_idx) * (1 - reduction_percent / 100.0))\n",
    "    # sampled_0_idx = np.random.choice(class_0_idx, size=n_keep, replace=False)\n",
    "    # # Combine sampled class 0 with all class 1\n",
    "    # final_idx = np.concatenate([sampled_0_idx, class_1_idx])\n",
    "    # x_train = x_train[final_idx]\n",
    "    # y_train =  y_train[final_idx]\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=100,  # match LightGBM\n",
    "    #     learning_rate=0.001,  # match LightGBM\n",
    "    #     max_depth=4,  # similar to LightGBM default tree depth\n",
    "    #     subsample=1.0,  # default\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "\n",
    "    # ----- XGBoost\n",
    "    # model = XGBClassifier()\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Random Forest\n",
    "    # model = RandomForestClassifier(\n",
    "    #     n_estimators=250,  # number of trees\n",
    "    #     max_depth=None,  # let the trees grow fully\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- SVM\n",
    "    # model = SVC(kernel='rbf', probability=True, random_state=seed)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- DT\n",
    "    # model = DecisionTreeClassifier(criterion=\"log_loss\", max_depth=512, random_state=seed)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict(x_test)\n",
    "\n",
    "\n",
    "    # MLP\n",
    "    # model = MLPClassifier(\n",
    "    #     hidden_layer_sizes=(128, 64),    # 2 hidden layers: 64 and 32 neurons\n",
    "    #     activation='relu',              # good default: 'relu'\n",
    "    #     solver='adam',                  # optimizer\n",
    "    #     alpha=0.0001,                   # L2 regularization\n",
    "    #     learning_rate_init=0.001,\n",
    "    #     max_iter=500,\n",
    "    #     early_stopping=True,\n",
    "    #     random_state=seed,\n",
    "    #     verbose=True,\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)    \n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    # y_preds = model.predict(x_test)\n",
    "\n",
    "\n",
    "    # LR\n",
    "    model = LogisticRegression(\n",
    "    penalty='l2',               # regularization (default)\n",
    "    C=1.0,                      # inverse of regularization strength\n",
    "    solver='lbfgs',             # optimizer (good default for small/medium data)\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=seed)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    y_preds = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS = np.append(Y_PROBS, y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, y_preds)\n",
    "\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "auc_roc = roc_auc_score(Y_TRUES, Y_PROBS)\n",
    "precision, recall, _ = precision_recall_curve(Y_TRUES, Y_PROBS)\n",
    "auc_pr = auc(recall, precision)\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "pre = precision_score(Y_TRUES, Y_PREDS)\n",
    "rec = recall_score(Y_TRUES, Y_PREDS)\n",
    "f1 = f1_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix: [ [TN, FP], [FN, TP] ]\n",
    "tn, fp, fn, tp = confusion_matrix(Y_TRUES, Y_PREDS).ravel()\n",
    "\n",
    "# Sensitivity = Recall = TP / (TP + FN)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# Specificity = TN / (TN + FP)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR:     {auc_pr:.4f}\")\n",
    "print(f\"Accuracy:   {acc:.4f}\")\n",
    "print(f\"Precision:  {pre:.4f}\")\n",
    "print(f\"Recall:     {rec:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"Specificity:          {specificity:.4f}\")\n",
    "print(confusion_matrix(Y_TRUES, Y_PREDS))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(Y_TRUES, 'o', color='blue', alpha=.25, markersize=8, label='Ground-truth')\n",
    "# plt.plot(Y_PREDS, 'o', color='red', alpha=.25, markersize=8, label='Prediction')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0 10779 11\n",
      "5 1 10617 173\n",
      "5 2 10488 302\n",
      "5 3 10599 191\n",
      "5 4 10604 186\n",
      "5 5 10767 23\n",
      "5 6 10437 353\n",
      "5 7 10541 249\n",
      "5 8 10500 290\n",
      "5 9 10611 179\n",
      "5 10 10771 19\n",
      "5 11 10560 230\n",
      "5 12 10532 258\n",
      "5 13 10716 74\n",
      "5 14 10524 266\n",
      "5 15 10548 242\n",
      "5 16 10665 125\n",
      "5 17 10508 282\n",
      "5 18 10668 122\n",
      "5 19 10570 220\n",
      "5 20 10588 202\n",
      "5 21 10521 269\n",
      "5 22 10627 163\n",
      "5 23 10600 190\n",
      "5 24 10771 19\n",
      "5 25 10520 270\n",
      "5 26 10495 295\n",
      "5 27 10520 270\n",
      "5 28 10605 185\n",
      "5 29 10616 174\n",
      "5 30 10576 214\n",
      "5 31 10556 234\n",
      "5 32 10687 103\n",
      "5 33 10560 230\n",
      "5 34 10625 165\n",
      "5 35 10751 39\n",
      "5 36 10525 265\n",
      "5 37 10436 354\n",
      "5 38 10621 169\n",
      "5 39 10463 327\n",
      "5 40 10524 266\n",
      "5 41 10584 206\n",
      "5 42 10632 158\n",
      "5 43 10520 270\n",
      "5 44 10728 62\n",
      "5 45 10699 91\n",
      "5 46 10763 27\n",
      "5 47 10580 210\n",
      "5 48 10672 118\n",
      "5 49 10528 262\n",
      "5 50 10627 163\n",
      "5 51 10541 249\n",
      "5 52 10502 288\n",
      "5 53 10575 215\n",
      "5 54 10532 258\n",
      "5 55 10775 15\n",
      "AUC-ROC (macro):     0.8358\n",
      "AUC-ROC (weighted):  0.9077\n",
      "AUC-PR  (macro):     0.2785\n",
      "AUC-PR  (weighted):  0.9772\n",
      "Accuracy:            0.5716\n",
      "Confusion Matrix:\n",
      "[[6090 3140 1266   70]\n",
      " [  10   24   37   46]\n",
      " [   5   12   42   30]\n",
      " [   0    0    6   12]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Y_TRUES = np.empty([0])\n",
    "Y_PROBS = []\n",
    "Y_PREDS = np.empty([0])\n",
    "\n",
    "\n",
    "cv = LeavePGroupsOut(n_groups=1)\n",
    "for train_idx, test_idx in cv.split(x, y, groups=p):\n",
    "    participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=x.shape[0], shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = np.unique(p[test_idx])[0]\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# for fold, (train_idx, test_idx) in enumerate(cv.split(x), start=1):\n",
    "#     participant = fold\n",
    "\n",
    "    x_train, x_test = x[train_idx], x[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(fold, participant, x_train.shape[0], x_test.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    x_train = normalizer.transform(x_train)\n",
    "    x_test = normalizer.transform(x_test)\n",
    "\n",
    "    # Oversample class 1\n",
    "\n",
    "    # ros = RandomOverSampler(sampling_strategy=.1, random_state=seed)\n",
    "    # x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "    # # 1. Check original class distribution\n",
    "    # print(\"Original class distribution:\", Counter(y_train))\n",
    "    # # 2. Define the minority class (adjust if needed)\n",
    "    # minority_class = 1  # change this if your minority class label is different\n",
    "    # current_minority_count = sum(y_train == minority_class)\n",
    "    # # 3. Define desired new total count for the minority class (10x)\n",
    "    # target_minority_count = current_minority_count * 10\n",
    "    # # 4. Setup SMOTE with custom sampling strategy\n",
    "    # smote = SMOTE(sampling_strategy={minority_class: target_minority_count}, random_state=seed)\n",
    "    # # 5. Fit and resample\n",
    "    # x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "    # # 6. Confirm new distribution\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # Undersample class 0\n",
    "    # reduction_percent = 99\n",
    "    # print(\"Original class distribution:\", Counter(y_train))    \n",
    "    # class_0_idx = np.where(y_train == 0)[0]\n",
    "    # class_1_idx = np.where(y_train == 1)[0]\n",
    "    # # How many class 0 samples to keep\n",
    "    # n_keep = int(len(class_0_idx) * (1 - reduction_percent / 100.0))\n",
    "    # sampled_0_idx = np.random.choice(class_0_idx, size=n_keep, replace=False)\n",
    "    # # Combine sampled class 0 with all class 1\n",
    "    # final_idx = np.concatenate([sampled_0_idx, class_1_idx])\n",
    "    # x_train = x_train[final_idx]\n",
    "    # y_train =  y_train[final_idx]\n",
    "    # print(\"Resampled class distribution:\", Counter(y_train))\n",
    "\n",
    "\n",
    "    # ----- LightGBM\n",
    "    # train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    # test_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n",
    "    # params = {\n",
    "    #     'verbose': -1,  # 👈 turn off training output\n",
    "    #     'objective': 'binary',\n",
    "    #     'metric': 'binary_logloss',  # or 'auc' if you prefer\n",
    "    #     'num_leaves': 64,\n",
    "    #     'learning_rate': 0.01,\n",
    "    #     'n_estimators': 100,\n",
    "    #     # 'is_unbalance': True  # Automatically balances positive and negative classes\n",
    "    #     # 'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    # }\n",
    "    # bst = lgb.train(params, train_data, valid_sets=[train_data, test_data])\n",
    "    # y_probs = bst.predict(x_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "\n",
    "    # ----- Transformer\n",
    "    # model = TabPFNClassifier(\n",
    "    #     device='cuda',\n",
    "    #     random_state=seed,\n",
    "    #     n_estimators = 4,\n",
    "    #     ignore_pretraining_limits=True)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Gradient Boosting Classifier\n",
    "    # model = GradientBoostingClassifier(\n",
    "    #     n_estimators=100,  # match LightGBM\n",
    "    #     learning_rate=0.001,  # match LightGBM\n",
    "    #     max_depth=4,  # similar to LightGBM default tree depth\n",
    "    #     subsample=1.0,  # default\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "\n",
    "    # ----- XGBoost\n",
    "    # model = XGBClassifier()\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- Random Forest\n",
    "    # model = RandomForestClassifier(\n",
    "    #     n_estimators=250,  # number of trees\n",
    "    #     max_depth=None,  # let the trees grow fully\n",
    "    #     random_state=seed\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- SVM\n",
    "    # model = SVC(kernel='rbf', probability=True, random_state=seed)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    # ----- DT\n",
    "    # model = DecisionTreeClassifier(criterion=\"log_loss\", max_depth=512, random_state=seed)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_probs = model.predict(x_test)\n",
    "\n",
    "\n",
    "    # MLP\n",
    "    # model = MLPClassifier(\n",
    "    #     hidden_layer_sizes=(128, 64),    # 2 hidden layers: 64 and 32 neurons\n",
    "    #     activation='relu',              # good default: 'relu'\n",
    "    #     solver='adam',                  # optimizer\n",
    "    #     alpha=0.0001,                   # L2 regularization\n",
    "    #     learning_rate_init=0.001,\n",
    "    #     max_iter=500,\n",
    "    #     early_stopping=True,\n",
    "    #     random_state=seed,\n",
    "    #     verbose=True,\n",
    "    # )\n",
    "    # model.fit(x_train, y_train)    \n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    # y_preds = model.predict(x_test)\n",
    "\n",
    "\n",
    "    # LR\n",
    "    # model = LogisticRegression(\n",
    "    # penalty='l2',               # regularization (default)\n",
    "    # C=1.0,                      # inverse of regularization strength\n",
    "    # solver='lbfgs',             # optimizer (good default for small/medium data)\n",
    "    # max_iter=1000,\n",
    "    # class_weight='balanced',\n",
    "    # random_state=seed)\n",
    "    # model.fit(x_train, y_train)    \n",
    "    # y_probs = model.predict_proba(x_test)[:, 1]\n",
    "    # y_preds = model.predict(x_test)\n",
    "\n",
    "\n",
    "    # NB\n",
    "    model = GaussianNB()\n",
    "    model.fit(x_train,\n",
    "              y_train,\n",
    "              sample_weight=compute_sample_weight(class_weight='balanced', y=y_train),\n",
    "              )\n",
    "    y_probs = model.predict_proba(x_test)\n",
    "    y_preds = model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "    Y_TRUES = np.append(Y_TRUES, y_test)\n",
    "    Y_PROBS.append(y_probs)\n",
    "    Y_PREDS = np.append(Y_PREDS, np.argmax(y_probs, axis=1))\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "Y_PROBS = np.concatenate(Y_PROBS, axis=0)\n",
    "\n",
    "\n",
    "indx = Y_TRUES.argsort()\n",
    "Y_TRUES = Y_TRUES[indx]\n",
    "Y_PROBS = Y_PROBS[indx]\n",
    "Y_PREDS = Y_PREDS[indx]\n",
    "\n",
    "\n",
    "# Evaluation metrics (multiclass)\n",
    "auc_roc_macro = roc_auc_score(Y_TRUES, Y_PROBS, multi_class='ovr', average='macro')\n",
    "auc_roc_weighted = roc_auc_score(Y_TRUES, Y_PROBS, multi_class='ovr', average='weighted')\n",
    "\n",
    "auc_pr_macro = average_precision_score(Y_TRUES, Y_PROBS, average='macro')\n",
    "auc_pr_weighted = average_precision_score(Y_TRUES, Y_PROBS, average='weighted')\n",
    "\n",
    "acc = accuracy_score(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(Y_TRUES, Y_PREDS)\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC-ROC (macro):     {auc_roc_macro:.4f}\")\n",
    "print(f\"AUC-ROC (weighted):  {auc_roc_weighted:.4f}\")\n",
    "print(f\"AUC-PR  (macro):     {auc_pr_macro:.4f}\")\n",
    "print(f\"AUC-PR  (weighted):  {auc_pr_weighted:.4f}\")\n",
    "print(f\"Accuracy:            {acc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ali-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
